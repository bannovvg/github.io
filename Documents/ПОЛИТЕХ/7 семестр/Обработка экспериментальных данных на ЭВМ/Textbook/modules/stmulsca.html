<html>

<head>
<title>Многомерное шкалирование</title>
</head>

<body BACKGROUND="../tile1.gif">
<font SIZE="5" COLOR="AA0000"><b>

<p align="center">Многомерное шкалирование</b></font></p>

<hr SIZE="1">

<ul>
  <li><a href="stmulsca.html#general">Общая цель</a></li>
  <li><a href="stmulsca.html#logic">Логика многомерного
    шкалирования</a></li>
  <li><a href="stmulsca.html#computational">Вычислительные методы</a></li>
  <li><a href="stmulsca.html#how">Задание размерности
    пользователем</a></li>
  <li><a href="stmulsca.html#interpreting">Интерпретация осей
    координат</a></li>
  <li><a href="stmulsca.html#applications">Приложения</a></li>
  <li><a href="stmulsca.html#mds">Многомерное шкалирование и
    факторный анализ</a></li>
</ul>

<hr SIZE="1">

<p><a NAME="general"></a><br>
<font size="4" color="#000080">Общая цель</font></p>

<p>Многомерное шкалирование (МНШ) можно
рассматривать как альтернативу факторному
анализу (см. <a href="stfacan.html"><em>Факторный анализ</em></a>).
Целью последнего, вообще говоря, является поиск и
интерпретация &quot;латентных (т.е. непосредственно
не наблюдаемых) переменных&quot;, дающих
возможность пользователю объяснить сходства
между объектами, заданными точками в исходном
пространстве признаков. Для определенности и
краткости, далее, как правило, будем говорить
лишь о сходствах объектов, имея ввиду, что на
практике это могут быть различия, расстояния или
степени связи между ними. В факторном анализе
сходства между объектами (например, переменными)
выражаются с помощью матрицы (таблицы)
коэффициентов корреляций. В методе МНШ
дополнительно к корреляционным матрицам, в
качестве исходных данных можно использовать
произвольный тип матрицы сходства объектов.
Таким образом, на входе всех алгоритмов МНШ
используется матрица, элемент которой на
пересечении ее i-й строки и j-го столбца, содержит
сведения о попарном сходстве анализируемых
объектов (объекта [i] и объекта [j]). На выходе
алгоритма МНШ получаются числовые значения
координат, которые приписываются каждому
объекту в некоторой новой системе координат (во
&quot;вспомогательных шкалах&quot;, связанных с
латентными переменными, откуда и название МНШ),
причем размерность нового пространства
признаков существенно меньше размерности
исходного (за это собственно и идет борьба).</p>

<table ALIGN="RIGHT">
  <tr>
    <td><a HREF="stmulsca.html#index"><font SIZE="1">В начало</font></a> </td>
  </tr>
</table>

<p><br CLEAR="RIGHT">
<a NAME="logic"></a> <br>
<font size="4" color="#000080">Логика многомерного
шкалирования</font></p>

<p>Логику МНШ можно проиллюстрировать на
следующем простом примере. Предположим, что
имеется матрица попарных расстояний (т.е.
сходства некоторых признаков) между крупными
американскими городами. Анализируя матрицу,
стремятся расположить точки с координатами
городов в двумерном пространстве (на плоскости),
максимально сохранив реальные расстояния между
ними. Полученное размещение точек на плоскости
впоследствии можно использовать в качестве
приближенной географической карты США.</p>

<p>В общем случае метод МНШ позволяет таким
образом расположить &quot;объекты&quot; (города в
нашем примере) в пространстве некоторой
небольшой размерности (в данном случае она равна
двум), чтобы достаточно адекватно воспроизвести
наблюдаемые расстояния между ними. В результате
можно &quot;измерить&quot; эти расстояния в терминах
найденных латентных переменных. Так, в нашем
примере можно объяснить расстояния в терминах
пары географических координат Север/Юг и
Восток/Запад.</p>

<p><strong>Ориентация осей координат.</strong> Как и в
Факторном анализе, ориентация осей может быть
выбрана произвольной. Возвращаясь к нашему
примеру, можно поворачивать карту США
произвольным образом, но расстояния между
городами при этом не изменятся. Таким образом,
окончательная ориентация осей на плоскости или в
пространстве является, в большей степени
результатом содержательного решения в
конкретной предметной области (т.е. решением
пользователя, который выберет такую ориентацию
осей, которую легче всего интерпретировать). В
примере можно было бы выбрать ориентацию осей,
отличающуюся от пары Север/Юг и Восток/Запад,
однако последняя удобнее, как &quot;наиболее
осмысленная&quot; и естественная.</p>

<table ALIGN="RIGHT">
  <tr>
    <td><a HREF="stmulsca.html#index"><font SIZE="1">В начало</font></a> </td>
  </tr>
</table>

<p><br CLEAR="RIGHT">
<a NAME="computational"></a> <br>
<font size="4" color="#000080">Вычислительные методы</font></p>

<p>Многомерное шкалирование - это не просто
определенная процедура, а скорее способ наиболее
эффективного размещения объектов, приближенно
сохраняющий наблюдаемые между ними расстояния.
Другими словами, МНШ размещает объекты в
пространстве заданной размерности и проверяет,
насколько точно полученная конфигурация
сохраняет расстояния между объектами. Говоря
более техническим языком, МНШ использует <a href="../glossary/gloss_a.html#Algorithm">алгоритм</a>
минимизации некоторой функции, оценивающей
качество получаемых вариантов отображения. </p>

<p><strong>Меры качества отображения:</strong> стресс.
Мерой, наиболее часто используемой для оценки
качества подгонки модели (отображения),
измеряемого по степени воспроизведения исходной
матрицы сходств, является так называемый стресс.
Величина стресса <em>Phi</em> в для текущей
конфигурации определяется так:</p>

<p><font color="blue">Phi = <img src="../graphics/sigmablu.gif" align="absmiddle" WIDTH="12" HEIGHT="19">[d<sub>ij</sub>
- f (<img src="../graphics/deltablu.gif" align="absmiddle" WIDTH="15" HEIGHT="17"><sub>ij</sub>)]<sup>2</sup> </font></p>

<p>Здесь <font color="blue"><i>d<sub>ij</sub></i></font> -
воспроизведенные расстояния в пространстве
заданной размерности, а <img SRC="../graphics/deltablu.gif" ALIGN="ABSMIDDLE" WIDTH="15" HEIGHT="17"><font color="blue"><sub>ij</sub></font> (<font color="blue"><i>дельта<sub>ij</sub></i></font>)
- исходное расстояние. Функция <font color="blue"><i>f</i> (<img SRC="../graphics/deltablu.gif" ALIGN="ABSMIDDLE" WIDTH="15" HEIGHT="17"><sub>ij</sub>)</font>
обозначает <em>неметрическое</em> монотонное
преобразование исходных данных (расстояний).
Таким образом, МНШ воспроизводит не
количественные меры сходств объектов, а лишь их
относительный порядок.</p>

<p>Обычно используется одна из несколько похожих
мер сходства. Тем не менее, большинство из них
сводится к вычислению суммы квадратов
отклонений наблюдаемых расстояний (либо их
некоторого монотонного преобразования) от
воспроизведенных расстояний. Таким образом, чем
меньше значение стресса, тем лучше матрица
исходных расстояний согласуется с матрицей
результирующих расстояний.</p>

<p><strong>Диаграмма Шепарда.</strong> Можно построить
для текущей конфигурации точек график
зависимости воспроизведенных расстояния от
исходных расстояний. Такая диаграмма рассеяния
называется диаграммой <em>Шепарда</em>. По оси
ординат OY показываются воспроизведенные
расстояния (сходства), а по оси OX откладываются
истинные сходства (расстояния) между объектами
(отсюда обычно получается отрицательный наклон).
На этом график также строится график ступенчатой
функции. Ее линия представляет так называемые
величины D-с крышечкой, то есть, результат
монотонного преобразования f(<img SRC="../graphics/delij.gif" ALIGN="ABSMIDDLE" WIDTH="16" HEIGHT="18">) исходных данных. Если бы все
воспроизведенные результирующие расстояния
легли на эту ступенчатую линию, то ранги
наблюдаемых расстояний (сходств) был бы в
точности воспроизведен полученным решением
(пространственной моделью). Отклонения от этой
линии показывают на ухудшение качества согласия
(т.е. качества подгонки модели). </p>

<table ALIGN="RIGHT">
  <tr>
    <td><a HREF="stmulsca.html#index"><font SIZE="1">В начало</font></a> </td>
  </tr>
</table>

<p><br CLEAR="RIGHT">
<a NAME="how"></a> <br>
<font size="4" color="#000080">Задание размерности
пользователем</font></p>

<p>Если вы уже знакомы с факторным анализом, вы
вполне можете пропустить этот раздел. В
противном случае вы можете перечитать раздел <a href="stfacan.html">Факторный анализ</a>. Однако это не
является необходимым для понимания идей
многомерного шкалирования.</p>

<p>Вообще говоря, чем больше размерность
пространства, используемого для воспроизведения
расстояний, тем лучше согласие воспроизведенной
матрицы с исходной (меньше значение стресса).
Если взять размерность пространства равной
числу переменных, то возможно абсолютно точное
воспроизведение исходной матрицы расстояний.
Однако нашей целью является упрощение решаемой
задачи, с тем, чтобы объяснить матрицу сходства
(расстояний) в терминах лишь нескольких
важнейших факторов (латентных переменных или
вспомогательных шкал). Возвращаясь к нашему
примеру с расстояниями между городами, если
получена двумерная карта, намного проще
представить себе расположение городов и
планировать передвижение между ними, чем если бы
имелась только матрица попарных расстояний.</p>

<p><strong>Причины плохого качества отображения.</strong>
Обсудим, почему уменьшение числа факторов (или
вспомогательных шкал) может приводить к
ухудшению представления исходной матрицы.
Обозначим буквами A, B, C и D, E, F две тройки городов.
Соответствующие им точки и попарные расстояния
между ними показаны в двух табличках (матрицах).</p>

<table>
  <tr>
    <th></th>
    <th align="right" width="15"><font color="blue">A</font></th>
    <th align="right" width="15"><font color="blue">B</font></th>
    <th align="right" width="15"><font color="blue">C</font></th>
    <th width="30" rowspan="2"></th>
    <th></th>
    <th align="right" width="15"><font color="blue">D</font></th>
    <th align="right" width="15"><font color="blue">E</font></th>
    <th align="right" width="15"><font color="blue">F</font></th>
  </tr>
  <tr>
    <th width="20"><font color="blue">A<br>
    B<br>
    C</font></th>
    <td align="right"><font color="blue">0<br>
    90<br>
    90</font></td>
    <td align="right"><font color="blue">&nbsp;<br>
    0<br>
    90</font></td>
    <td align="right"><font color="blue">&nbsp;<br>
    &nbsp;<br>
    90</font></td>
    <th><font color="blue">D<br>
    E<br>
    F</font></th>
    <td align="right"><font color="blue">0<br>
    90<br>
    180</font></td>
    <td align="right"><font color="blue">&nbsp;<br>
    0<br>
    90</font></td>
    <td align="right"><font color="blue">&nbsp;<br>
    &nbsp;<br>
    0</font></td>
  </tr>
</table>

<p><br>
Первой матрице соответствует случай когда
города удалены друг от друга в точности на 90
километров, а второй - когда города <font color="blue"><i><b>D</b></i></font>
и <font color="blue"><i><b>F</b></i></font> удаляются на 180
километров. Можно ли три точки, соответствующие
городам (объектам) расположить в одномерном
пространстве (на прямой)? Действительно, три
точки, соответствующие городам <font color="blue"><i><b>D</b></i></font>,
<font color="blue"><b><i>E</i></b></font> и <font color="blue"><i><b>F</b></i></font>
могут быть расположены на прямой линии:</p>

<p><font color="blue"><b>D</b>---90 км---<b>E</b>---90 км---<b>F</b> </font></p>

<p><font color="blue"><i><b>D</b></i></font> удален на 90 км от города <font color="blue"><b><i>E</i></b></font>, и <font color="blue"><b><i>E</i></b></font> - на
90 км от <font color="blue"><i><b>F</b></i></font>, а город <font color="blue"><i><b>D</b></i></font>
удален на 90+90=180 км от <em><b><font color="blue">F</font></b></em>.
Если попытаться проделать тоже самое с городами <font color="blue"><b><i>A</i></b></font>, <font color="blue"><b><i>B</i></b></font> и <font color="blue"><i><b>C</b></i></font>, то видно, что
соответствующие им точки уже нельзя разместить
на прямой с сохранением исходной структуры
расстояний. Однако эти точки можно расположить
на плоскости, например, в виде треугольника:</p>

<table>
  <tr>
    <td colspan="3" align="center"><font color="blue"><b>A</b></font></td>
  </tr>
  <tr>
    <td align="center"><font color="blue">90 км</font></td>
    <td></td>
    <td align="center"><font color="blue">90 км</font></td>
  </tr>
  <tr>
    <td align="center"><font color="blue"><b>B</b></font></td>
    <td align="center"><font color="blue">90 км</font></td>
    <td align="center"><font color="blue"><b>C</b></font></td>
  </tr>
</table>

<p>Располагая эти три точки так, можно в точности
воспроизвести все расстояния между ними. Без
лишних деталей, этот пример показывает, как
конкретная матрица расстояний (сходств) связана
с числом искомых латентных переменных
(размерностью результирующего пространства).
Конечно, &quot;реальные&quot; данные никогда не
являются такими &quot;точными&quot;, и содержат
случайный шум, т.е. случайную изменчивость,
влияющую на различие между воспроизведенной и
исходной матрицей.</p>

<p><strong>Критерий &quot;каменистой осыпи&quot;.</strong>
Обычно, для выбора размерности пространства, в
котором будет воспроизводится наблюдаемая
матрица, используют график зависимости стресса
от размерности (график каменистой осыпи). Этот
критерий впервые был предложен Кэттелом (Cattell
(1966)) в контексте решения задачи снижения
размерности в факторном анализе (см. <em><a href="stfacan.html#results">Факторный анализ</a></em>); Краскал и
Виш (Kruskal and Wish (1978; стр. 53-60)) обсуждали применение
этого графика в методе МНШ.</p>

<p>Кэттел предложил найти такую абсциссу на
графике (в методе ФА, по оси абсцисс идут
собственные значения), в которой график стресса
начинает визуально сглаживаться в направлении
правой, пологой его части, и, таким образом,
уменьшение стресса максимально замедляется.
Образно говоря, линия на рисунке напоминает
скалистый обрыв, а черные точки на графике
напоминают камни, которые ранее упали вниз. Таким
образом, внизу наблюдается как бы каменистая
осыпь из таких точек. Справа от выбранной точки
на оси абсцисс, лежит только &quot;факторная
осыпь&quot;. Согласно этому критерию, на
приведенном рисунке, скорее всего, следует
выбрать для воспроизведения двумерное
пространство.</p>

<p><strong>Интерпретируемость конфигурации.</strong>
Вторым критерием для решения вопроса о
размерности с целью интерпретации является
&quot;ясность&quot; полученной конфигурации точек.
Иногда, как в нашем примере с городами,
результирующие координаты легко
интерпретируются. В других случаях, точки на
графике могут образовывать ту или иную
разновидность &quot;случайного облака&quot;, и не
существует непосредственного способа для
интерпретации латентных переменных. В последнем
случае следует постараться немного увеличить
число координатных осей и рассмотреть
получаемые в результате конфигурации. Чаще
всего, получаемые решения проще удается
проинтерпретировать. Однако если точки на
графике не следуют какому-либо образцу, а также
если график стресса не показывает какого-либо
явного &quot;изгиба&quot; (и не похож на &quot;край
обрыва&quot;), то данные скорее всего являются
случайным &quot;шумом&quot;. </p>

<table ALIGN="RIGHT">
  <tr>
    <td><a HREF="stmulsca.html#index"><font SIZE="1">В начало</font></a> </td>
  </tr>
</table>

<p><br CLEAR="RIGHT">
<a NAME="interpreting"></a> <br>
<font size="4" color="#000080">Интерпретация осей координат</font></p>

<p>Интерпретация осей обычно представляет собой
заключительный этап анализа по методу
многомерного шкалирования. Как уже упоминалось
ранее, в принципе, ориентация осей в методе МНШ
может быть произвольной, и систему координат
можно повернуть в любом направлении. Поэтому на
первом шаге получают диаграмму рассеяния точек,
соответствующих объектам, на различных
плоскостях.</p>

<p><img BORDER="0" SRC="../popups/popup16.gif" alt="Диаграмма рассеяния" WIDTH="306" HEIGHT="218"></p>

<p>Трехмерные решения также можно
проинтерпретировать графически.</p>

<p><img BORDER="0" SRC="../popups/popup80.gif" alt="Трехмерный график" WIDTH="306" HEIGHT="226"></p>

<p>Однако эта интерпретация является несколько
более сложной.<br>
Заметим, что в дополнение к существенным осям
координат, также следует искать кластеры точек, а
также те или иные конфигурации точек (окружности,
многообразия и др.). Более подробное обсуждение
интерпретации полученных конфигураций, см. в
работах Borg and Lingoes (1987), Borg and Shye (в печати) или Gutman,
(1968). </p>

<p><strong>Использование методов множественной
регрессии.</strong> Аналитическим способом
интерпретации осей координат (описанным в работе
Kruskal и Wish, 1978) является применение методов
множественной регрессии для регрессирования
некоторых имеющих смысл переменных на оси
координат. Это легко сделать с помощью модуля <a href="stmulreg.html">Множественная регрессия</a>. </p>

<table ALIGN="RIGHT">
  <tr>
    <td><a HREF="stmulsca.html#index"><font SIZE="1">В начало</font></a> </td>
  </tr>
</table>

<p>&nbsp;</p>

<p><br CLEAR="RIGHT">
<a NAME="applications"></a> <br>
<font size="4" color="#000080">Приложения</font></p>

<p>&quot;Красота&quot; метода МНШ в том, что вы можете
анализировать произвольный тип матрицы
расстояний или сходства. Эти сходства могут
представлять собой оценки экспертов
относительно сходства данных объектов,
результаты измерения расстояний в некоторой
метрике, процент согласия между судьями по
поводу принимаемого решения, количество раз,
когда субъект затрудняется различить стимулы и
мн.др. Например, методы МНШ весьма популярны в
психологическом исследовании восприятия
личности. В этом исследовании анализируются
сходства между определенными чертами характера
с целью выявления основополагающими личностных
качеств (см., например, Rosenberg, 1977). Также они
популярны в маркетинговых исследованиях, где их
используют для выявления числа и сущности
латентных переменных (факторов), например, с
целью с целью изучения отношения людей к товарам
известных торговых марок (подробнее см. Green и Carmone,
1970).</p>

<p>В общем случае, методы МНШ позволяют
исследователю задать клиентам в анкете
относительно ненавязчивые вопросы (&quot;насколько
похож товар фирмы A на товар фирмы B&quot;) и найти
латентные переменные для этих анкет незаметно
для респондентов.</p>

<table ALIGN="RIGHT">
  <tr>
    <td><a HREF="stmulsca.html#index"><font SIZE="1">В начало</font></a> </td>
  </tr>
</table>

<p>&nbsp;</p>

<p><br CLEAR="RIGHT">
<a NAME="mds"></a><br>
<font size="4" color="#000080">Многомерное шкалирование и
факторный анализ</font></p>

<p>Даже несмотря на то, что имеется много сходства
в характере исследуемых вопросов, методы МНШ и
факторного анализа имеют ряд существенных
отличий. Так, факторный анализ требует, чтобы
исследуемые данные подчинялись многомерному
нормальному распределению, а зависимости были
линейными. Методы МНШ не накладывают таких
ограничений. Методы МНШ могут быть применимы,
пока сохраняет смысл порядок следования рангов
сходств. В терминах различий получаемых
результатов, факторный анализ стремится извлечь
больше факторов (координатных осей или латентных
переменных) по сравнению с МНШ; в результате чего
МНШ часто приводит к проще интерпретируемым
решениям. Однако более существенно то, что методы
МНШ можно применять к любым типам расстояний или
сходств, тогда как методы ФА требуют, чтобы
первоначально была вычислена матрица
корреляций. Методы МНШ могут быть основаны на
прямом оценивании сходств между стимулами
субъектов, тогда как ФА требует, чтобы субъекты
были оценены через их стимулы по некоторому
списку атрибутов.</p>

<p>Суммируя вышесказанное, можно сказать, что
методы МНШ потенциально применимы к более
широкому классу исследовательских задач. </p>

<table ALIGN="RIGHT">
  <tr>
    <td><a HREF="stmulsca.html#index"><font SIZE="1">В начало</font></a> </td>
  </tr>
</table>

<p><br>
<br>
</p>

<hr SIZE="1">

<p align="center"><br>
<img SRC="../stathoms.jpg" ALIGN="LEFT" WIDTH="151" HEIGHT="41"> <br CLEAR="ALL">
<font SIZE="1">(c) Copyright StatSoft, Inc., 1984-2001<br>
STATISTICA является торговой маркой StatSoft, Inc. </font></p>

<hr SIZE="1">
</body>
</html>
