<html>

<head>
<title>Главные компоненты и факторный анализ</title>
</head>

<body BACKGROUND="../tile1.gif">
<font SIZE="5" COLOR="AA0000"><b>

<p align="center">Главные компоненты и факторный анализ</b></font></p>

<hr SIZE="1">

<ul>
  <p><a NAME="index"></a></p>
  <li><a HREF="stfacan.html#general">Основная цель</a> </li>
  <li><a HREF="stfacan.html#basic">Факторный анализ как метод
    редукции данных</a> </li>
  <li><a HREF="stfacan.html#factor">Факторный анализ как метод
    классификации</a> </li>
  <li><a HREF="stfacan.html#sundries">Другие результаты и
    статистики</a> </li>
</ul>

<hr SIZE="1">

<p><a NAME="general"></a></p>
<font SIZE="4" COLOR="navy">

<p>Основная цель </font></p>

<p>Главными целями факторного анализа являются: (1)
<i>сокращение </i>числа переменных (редукция
данных) и (2) <i>определение структуры</i>
взаимосвязей между переменными, т.е. <i>классификация
переменных</i>. Поэтому факторный анализ
используется или как метод сокращения данных или
как метод классификации. Ниже описываются
принципы факторного анализа и способы его
применения для достижения этих двух целей.
Предполагается, что вы знакомы с логикой
статистических выводов в объеме, содержащемся в
разделе <a href="../esc.html"><i>Элементарные понятия
статистики</i></a>. Предполагается также, что вы
знакомы с понятиями дисперсии и корреляции (см.
например, раздел <a href="stbasic.html"><i>Основные
статистики и таблицы</i></a>). </p>

<p>Существует множество прекрасных книг по
факторному анализу. Практические примеры и
советы по применению можно, например, найти в
книге Стивенса (Stevens, 1986); более подробное
описание приводят Кули и Лонес (Cooley, Lohnes, 1971);
Харман (Harman, 1976); Ким и Мюллер (Kim, Mueller, 1978a, 1978b);
Лоули и Максвелл (Lawley, Maxwell, 1971); Линдеман, Меренда
и Голд (Lindeman, Merenda, Gold, 1980); Моррисон (Morrison, 1967) и
Мулэйк (Mulaik, 1972). Интерпретация вторичных
факторов в иерархическом факторном анализе, как
альтернатива традиционному вращению факторов,
дана Верри (Wherry, 1984). </p>

<p><b>Подтверждающий факторный анализ. </b><a href="stsepath.html"><i>Моделирование структурными
уравнениями (SEPATH)</i></a> позволяет проверять
частные гипотезы о факторной структуре для
множества переменных (подтверждающий факторный
анализ) в одной или нескольких выборках
(например, вы сможете сравнить факторные
структуры разных выборок (опытов)). </p>

<p><b>Анализ соответствий. </b><a href="stcoran.html">Анализ
соответствий</a> - это описательные/разведочные
методы, предназначенные для анализа двух- и
многовходовых таблиц, содержащих некоторые
взаимосвязи между строками и столбцами.
Результаты этого анализа дают информацию,
похожую на ту, которую предоставляет факторный
анализ, и позволяют изучить структуру
категориальных переменных, входящих в таблицу.
За более полной информацией об этих методах
обратитесь к описанию <a href="stcoran.html"><i>Анализа
соответствий</i></a>. </p>

<table ALIGN="RIGHT">
  <tr>
    <td><font size="1"><a HREF="stfacan.html#index">В начало</a></font> </td>
  </tr>
</table>

<p><br CLEAR="RIGHT">
<a NAME="basic"></a> </p>

<p><font SIZE="4" COLOR="navy">Факторный анализ как метод
редукции данных </font></p>

<p>Предположим, что вы проводите (до некоторой
степени &quot;глупое&quot;) исследование, в котором
измеряете рост ста людей в дюймах и сантиметрах.
Таким образом, у вас имеются две переменные. Если
далее вы захотите исследовать, например, влияние
различных пищевых добавок на рост, будете ли вы
продолжать использовать <i>обе</i> переменные?
Вероятно, нет, т.к. рост является одной
характеристикой человека, независимо от того, в
каких единицах он измеряется. </p>

<p>Теперь предположим, вы хотите измерить
удовлетворенность людей жизнью, для чего
составляете вопросник с различными пунктами;
среди других вопросов задаете следующие:
удовлетворены ли люди своим хобби (пункт 1) и как
интенсивно они им занимаются (пункт 2). Результаты
преобразуются так, что средние ответы (например,
для удовлетворенности) соответствуют значению
100, в то время как ниже и выше средних ответов
расположены меньшие и большие значения,
соответственно. Две переменные (ответы на два
разных пункта) коррелированы между собой. (Если
вы не знакомы с понятием коэффициента
корреляции, рекомендуем обратиться к разделу <a href="stbasic.html#Correlations">Основные статистики и таблицы -
Корреляции</a>). Из высокой коррелированности двух
этих переменных можно сделать вывод об
избыточности двух пунктов опросника. </p>

<p><b>Объединение двух переменных в один фактор. </b>Зависимость
между переменными можно обнаружить с помощью <a href="../glossary/gloss_2m.html#Scatterplot, 2D">диаграммы
рассеяния</a>. Полученная путем подгонки линия
регрессии дает графическое представление
зависимости. Если определить новую переменную на
основе линии регрессии, изображенной на этой
диаграмме, то такая переменная будет включить в
себя наиболее существенные черты обеих
переменных. Итак, фактически, вы сократили число
переменных и заменили две одной. Отметим, что
новый фактор (переменная) в действительности
является линейной комбинацией двух исходных
переменных. </p>

<p><b>Анализ главных компонент. </b>Пример, в котором
две коррелированные переменные объединены в
один фактор, показывает главную идею факторного
анализа или, более точно, анализа главных
компонент (это различие будет обсуждаться
позднее). Если пример с двумя переменными
распространить на большее число переменных, то
вычисления становятся сложнее, однако основной
принцип представления двух или более зависимых
переменных одним фактором остается в силе. </p>

<p><b>Выделение главных компонент. </b>В основном
процедура выделения главных компонент подобна <i>вращению,
максимизирующему дисперсию (варимакс)</i>
исходного пространства переменных. Например, на
диаграмме рассеяния вы можете рассматривать
линию регрессии как ось <i>X</i>, повернув ее так, что
она совпадает с прямой регрессии. Этот тип
вращения называется <i>вращением,
максимизирующим дисперсию,</i> так как критерий
(цель) вращения заключается в максимизации
дисперсии (изменчивости) &quot;новой&quot; переменной
(фактора) и минимизации разброса вокруг нее (см. <i>Стратегии
вращения</i>). </p>

<p><b>Обобщение на случай многих переменных.</b> В
том случае, когда имеются более двух переменных,
можно считать, что они определяют трехмерное
&quot;пространство&quot; точно так же, как две
переменные определяют плоскость. Если вы имеете
три переменные, то можете построить 3М диаграмму
рассеяния. </p>

<p><img BORDER="0" SRC="../popups/popup14.gif" alt="3М диаграмма рассеяния" WIDTH="306" HEIGHT="218"> </p>

<p>Для случая более трех переменных, становится
невозможным представить точки на диаграмме
рассеяния, однако логика вращения осей с целью
максимизации дисперсии нового фактора остается
прежней. </p>

<p><b>Несколько ортогональных факторов.</b> После
того, как вы нашли линию, для которой дисперсия
максимальна, вокруг нее остается некоторый
разброс данных. И процедуру естественно
повторить. В анализе главных компонент именно
так и делается: после того, как первый фактор <i>выделен</i>,
то есть, после того, как первая линия проведена,
определяется следующая линия, максимизирующая
остаточную вариацию (разброс данных вокруг
первой прямой), и т.д. Таким образом, факторы
последовательно выделяются один за другим. Так
как каждый последующий фактор определяется так,
чтобы максимизировать изменчивость, оставшуюся
от предыдущих, то факторы оказываются
независимыми друг от друга. Другими словами,
некоррелированными или <i>ортогональными</i>. </p>

<p><b>Сколько факторов следует выделять? </b>Напомним,
что анализ главных компонент является методом
сокращения или редукции данных, т.е. методом
сокращения числа переменных. Возникает
естественный вопрос: сколько факторов следует
выделять? Отметим, что в процессе
последовательного выделения факторов они
включают в себя все меньше и меньше изменчивости.
Решение о том, когда следует остановить
процедуру выделения факторов, главным образом
зависит от точки зрения на то, что считать малой
&quot;случайной&quot; изменчивостью. Это решение
достаточно произвольно, однако имеются
некоторые рекомендации, позволяющие рационально
выбрать число факторов, как показано в <i>Обзоре
результатов анализа главных компонент</i>, см.
раздел <i>Собственные значения и задача о числе
факторов</i>. <a NAME="results"></a> </p>

<p><b>Обзор результатов анализа главных компонент. </b>Посмотрим
теперь на некоторые стандартные результаты
анализа главных компонент. При повторных
итерациях вы выделяете факторы с все меньшей и
меньшей дисперсией. Для простоты изложения
считаем, что обычно работа начинается с матрицы,
в которой дисперсии всех переменных равны <i>1.0</i>.
Поэтому общая дисперсия равна числу переменных.
Например, если вы имеете 10 переменных, каждая из
которых имеет дисперсию <i>1</i>, то наибольшая
изменчивость, которая потенциально может быть
выделена, равна 10 раз по 1. Предположим, что при
изучении степени удовлетворенности жизнью вы
включили 10 пунктов для измерения различных
аспектов удовлетворенности домашней жизнью и
работой. Дисперсия, объясненная
последовательными факторами, представлена в
следующей таблице: </p>

<table BORDER="1">
  <tr>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">STATISTICA<br>
    ФАКТОРНЫЙ<br>
    АНАЛИЗ</font></th>
    <th ALIGN="CENTER" COLSPAN="4"><font COLOR="BLUE" SIZE="2">Собственные
    значения (factor.sta)<br>
    Выделение: Главные компоненты<br>
    &nbsp;</font></th>
  </tr>
  <tr>
    <th ALIGN="CENTER"><font COLOR="BLUE" SIZE="2">&nbsp;<br>
    Значение</font></th>
    <th ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">Собственные<br>
    значения</font></th>
    <th ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">% общей<br>
    дисперсии</font></th>
    <th ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">Кумулят.<br>
    соб. знач.</font></th>
    <th ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">Кумулят.<br>
    %</font></th>
  </tr>
  <tr>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">1<br>
    2<br>
    3<br>
    4<br>
    5<br>
    6<br>
    7<br>
    8<br>
    9<br>
    10</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">6.118369<br>
    1.800682<br>
    .472888<br>
    .407996<br>
    .317222<br>
    .293300<br>
    .195808<br>
    .170431<br>
    .137970<br>
    .085334</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">61.18369<br>
    18.00682<br>
    4.72888<br>
    4.07996<br>
    3.17222<br>
    2.93300<br>
    1.95808<br>
    1.70431<br>
    1.37970<br>
    .85334</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">6.11837<br>
    7.91905<br>
    8.39194<br>
    8.79993<br>
    9.11716<br>
    9.41046<br>
    9.60626<br>
    9.77670<br>
    9.91467<br>
    10.00000</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">61.1837<br>
    79.1905<br>
    83.9194<br>
    87.9993<br>
    91.1716<br>
    94.1046<br>
    96.0626<br>
    97.7670<br>
    99.1467<br>
    100.0000</font></td>
  </tr>
</table>

<p><br CLEAR="ALL">
</p>

<p><b>Собственные значения</b><br>
Во втором столбце (<i>Собственные значения) </i>таблицы
результатов вы можете найти дисперсию нового,
только что выделенного фактора. В третьем
столбце для каждого фактора приводится процент
от общей дисперсии (в данном примере она равна <i>10</i>)
для каждого фактора. Как можно видеть, первый
фактор (значение 1) объясняет 61 процент общей
дисперсии, фактор 2 (значение 2) - 18 процентов, и т.д.
Четвертый столбец содержит накопленную или
кумулятивную дисперсию. Дисперсии, выделяемые
факторами, названы <i>собственными значениями</i>.
Это название происходит из использованного
способа вычисления. </p>

<p><b>Собственные значения и задача о числе
факторов</b><br>
Как только получена информация о том, сколько
дисперсии выделил каждый фактор, вы можете
возвратиться к вопросу о том, сколько факторов
следует оставить. Как говорилось выше, по своей
природе это решение произвольно. Однако имеются
некоторые общеупотребительные рекомендации, и
на практике следование им дает наилучшие
результаты. </p>

<p><b>Критерий Кайзера.</b> Сначала вы можете
отобрать только факторы, с собственными
значениями, большими <i>1</i>. По существу, это
означает, что если фактор не выделяет дисперсию,
эквивалентную, по крайней мере, дисперсии одной
переменной, то он опускается. Этот критерий
предложен Кайзером (Kaiser, 1960), и является, вероятно,
наиболее широко используемым. В приведенном выше
примере на основе этого критерия вам следует
сохранить только 2 фактора (две главные
компоненты). </p>

<p><b>Критерий каменистой осыпи. </b><i>Критерий
каменистой осыпи</i> является графическим
методом, впервые предложенным Кэттелем (Cattell, 1966).
Вы можете изобразить собственные значения,
представленные в таблице ранее, в виде простого
графика. </p>

<p><img BORDER="0" SRC="../popups/popup15.gif" alt="График каменистой осыпи" WIDTH="306" HEIGHT="218"> </p>

<p>Кэттель предложил найти такое место на графике,
где убывание собственных значений слева направо
максимально замедляется. Предполагается, что
справа от этой точки находится только
&quot;факториальная осыпь&quot; - &quot;осыпь&quot;
является геологическим термином, обозначающим
обломки горных пород, скапливающиеся в нижней
части скалистого склона. В соответствии с этим
критерием можно оставить в этом примере 2 или 3
фактора. </p>

<p><b>Какой критерий следует использовать. </b>Оба
критерия были изучены подробно Брауном (Browne, 1968),
Кэттелем и Джасперсом (Cattell, Jaspers, 1967), Хакстианом,
Рожерсом и Кэттелем (Hakstian, Rogers, Cattell, 1982), Линном
(Linn, 1968), Тюкером, Купманом и Линном (Tucker, Koopman, Linn,
1969). Теоретически, можно вычислить их
характеристики путем генерации случайных данных
для конкретного числа факторов. Тогда можно
увидеть, обнаружено с помощью используемого
критерия достаточно точное число существенных
факторов или нет. С использованием этого общего
метода первый критерий (<i>критерий Кайзера</i>)
иногда сохраняет слишком много факторов, в то
время как второй критерий (<i>критерий каменистой
осыпи</i>) иногда сохраняет слишком мало факторов;
однако оба критерия вполне хороши при нормальных
условиях, когда имеется относительно небольшое
число факторов и много переменных. На практике
возникает важный дополнительный вопрос, а
именно: когда полученное решение может быть
содержательно интерпретировано. Поэтому обычно
исследуется несколько решений с большим или
меньшим числом факторов, и затем выбирается одно
наиболее &quot;осмысленное&quot;. Этот вопрос далее
будет рассматриваться в рамках вращений
факторов. </p>

<p><b>Анализ главных факторов</b><br>
Прежде, чем продолжить рассмотрение различных
аспектов вывода анализа главных компонент,
введем анализ главных факторов. Вернемся к
примеру вопросника об удовлетворенности жизнью,
чтобы сформулировать другую &quot;мыслимую
модель&quot;. Вы можете представить себе, что ответы
субъектов зависят от двух компонент. Сначала
выбираем некоторые подходящие общие факторы,
такие как, например, &quot;удовлетворение своим
хобби&quot;, рассмотренные ранее. Каждый пункт
измеряет некоторую часть этого общего аспекта
удовлетворения. Кроме того, каждый пункт
включает уникальный аспект удовлетворения, не
характерный для любого другого пункта. </p>

<p><b>Общности. </b>Если эта модель правильна, то вы
не можете ожидать, что факторы будут содержать
всю дисперсию в переменных; они будут содержать
только ту часть, которая принадлежит общим
факторам и распределена по нескольким
переменным. На языке факторного анализа доля
дисперсии отдельной переменной, принадлежащая
общим факторам (и разделяемая с другими
переменными) называется <i>общностью</i>. Поэтому
дополнительной работой, стоящей перед
исследователем при применении этой модели,
является оценка общностей для каждой переменной,
т.е. доли дисперсии, которая является общей для
всех пунктов. Доля дисперсии, за которую отвечает
каждый пункт, равна тогда суммарной дисперсии,
соответствующей всем переменным, минус общность.
С общей точки зрения в качестве оценки общности
следует использовать множественный коэффициент
корреляции выбранной переменной со всеми
другими (для получения сведений о теории
множественной регрессии сошлемся на раздел <i>Множественная
регрессия</i>). Некоторые авторы предлагают
различные итеративные &quot;улучшения после
решения&quot; начальной оценки общности,
полученной с использованием множественной
регрессии; например, так называемый метод MINRES
(метод минимальных факторных остатков; Харман и
Джоунс (Harman, Jones, 1966)), который производит
испытание различных модификаций факторных
нагрузок с целью минимизации остаточных
(необъясненных) сумм квадратов. </p>

<p><b>Главные факторы в сравнении с главными
компонентами. </b>Главные факторы в сравнении с
главными компонентами. Основное различие двух
моделей факторного анализа состоит в том, что в
анализе главных компонент предполагается, что
должна быть использована <i>вся</i> изменчивость
переменных, тогда как в анализе главных факторов
вы используете только изменчивость переменной,
общую и для других переменных. Подробное
обсуждение всех &quot;за&quot; и &quot;против&quot; каждого
подхода находится за пределами данного введения.
В большинстве случаев эти два метода приводят к
весьма близким результатам. Однако анализ
главных компонент часто более предпочтителен
как метод сокращения данных, в то время как
анализ главных факторов лучше применять с целью
определения структуры данных (см. следующий
раздел). </p>

<table ALIGN="RIGHT">
  <tr>
    <td><font size="1"><a HREF="stfacan.html#index">В начало</a></font> </td>
  </tr>
</table>

<p><br CLEAR="RIGHT">
<a NAME="factor"></a> </p>

<p><font SIZE="4" COLOR="navy">Факторный анализ как метод
классификации </font></p>

<p>Возвратимся к интерпретации результатов
факторного анализа. Термин <i>факторный анализ </i>теперь
будет включать как анализ главных компонент, так
и анализ главных факторов. Предполагается, что вы
находитесь в той точке анализа, когда в целом
знаете, сколько факторов следует выделить. Вы
можете захотеть узнать значимость факторов, то
есть, можно ли интерпретировать их разумным
образом и как это сделать. Чтобы
проиллюстрировать, каким образом это может быть
сделано, производятся действия &quot;в обратном
порядке&quot;, то есть, начинают с некоторой
осмысленной структуры, а затем смотрят, как она
отражается на результатах. Вернемся к примеру об
удовлетворенности; ниже приведена
корреляционная матрица для переменных,
относящихся к удовлетворенности на работе и
дома. </p>

<table BORDER="1">
  <tr>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">STATISTICA<br>
    ФАКТОРНЫЙ<br>
    АНАЛИЗ</font></th>
    <th ALIGN="CENTER" COLSPAN="6"><font COLOR="BLUE" SIZE="2">Корреляции
    (factor.sta)<br>
    Построчное удаление ПД<br>
    n=100</font></th>
  </tr>
  <tr>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">Переменная</font></th>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">РАБОТА_1</font></th>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">РАБОТА_2</font></th>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">РАБОТА_3</font></th>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">ДОМ_1</font></th>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">ДОМ_2</font></th>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">ДОМ_3</font></th>
  </tr>
  <tr>
    <td ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">РАБОТА_1<br>
    РАБОТА_2<br>
    РАБОТА_3<br>
    ДОМ_1<br>
    ДОМ_2<br>
    ДОМ_3</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">1.00<br>
    .65<br>
    .65<br>
    .14<br>
    .15<br>
    .14</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.65<br>
    1.00<br>
    .73<br>
    .14<br>
    .18<br>
    .24</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.65<br>
    .73<br>
    1.00<br>
    .16<br>
    .24<br>
    .25</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.14<br>
    .14<br>
    .16<br>
    1.00<br>
    .66<br>
    .59</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.15<br>
    .18<br>
    .24<br>
    .66<br>
    1.00<br>
    .73</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.14<br>
    .24<br>
    .25<br>
    .59<br>
    .73<br>
    1.00</font></td>
  </tr>
</table>

<p><br CLEAR="ALL">
Переменные, относящиеся к удовлетворенности на
работе, более коррелированы между собой, а
переменные, относящиеся к удовлетворенности
домом, также более коррелированы между собой.
Корреляции между этими двумя типами переменных
(переменные, связанные с удовлетворенностью на
работе, и переменные, связанные с
удовлетворенностью домом) сравнительно малы.
Поэтому кажется правдоподобным, что имеются два
относительно независимых фактора (два типа
факторов), отраженных в корреляционной матрице:
один относится к удовлетворенности на работе, а
другой к удовлетворенности домашней жизнью. </p>

<p><b>Факторные нагрузки.</b> Теперь проведем анализ
главных компонент и рассмотрим решение с двумя
факторами. Для этого рассмотрим корреляции между
переменными и двумя факторами (или &quot;новыми&quot;
переменными), как они были выделены по умолчанию;
эти корреляции называются факторными <i>нагрузками</i>.
</p>

<table BORDER="1">
  <tr>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">STATISTICA<br>
    ФАКТОРНЫЙ<br>
    АНАЛИЗ</font></th>
    <th ALIGN="CENTER" COLSPAN="2"><font COLOR="BLUE" SIZE="2">Факторные
    нагрузки (Нет вращения)<br>
    Главные компоненты<br>
    &nbsp;</font></th>
  </tr>
  <tr>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">Переменная</font></th>
    <th ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">Фактор 1</font></th>
    <th ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">Фактор 2</font></th>
  </tr>
  <tr>
    <td ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">РАБОТА_1<br>
    РАБОТА_2<br>
    РАБОТА_3<br>
    ДОМ_1<br>
    ДОМ_2<br>
    ДОМ_3</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.654384<br>
    .715256<br>
    .741688<br>
    .634120<br>
    .706267<br>
    .707446</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.564143<br>
    .541444<br>
    .508212<br>
    -.563123<br>
    -.572658<br>
    -.525602</font></td>
  </tr>
  <tr>
    <td ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">Общая дисперсия<br>
    Доля общей дисп.</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">2.891313<br>
    .481885</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">1.791000<br>
    .298500</font></td>
  </tr>
</table>

<p><br CLEAR="ALL">
По-видимому, первый фактор более коррелирует с
переменными, чем второй. Это следовало ожидать,
потому что, как было сказано выше, факторы
выделяются последовательно и содержат все
меньше и меньше общей дисперсии. </p>

<p><b>Вращение факторной структуры.</b> Вы можете
изобразить факторные нагрузки в виде <a href="../glossary/gloss_2m.html#Scatterplot, 2D">диаграммы
рассеяния</a>. На этой диаграмме каждая переменная
представлена точкой. Можно повернуть оси в любом
направлении без изменения <i>относительного </i>положения
точек; однако действительные координаты точек,
то есть факторные нагрузки, должны, без сомнения,
меняться. Если вы построите диаграмму для этого
примера, то увидите, что если повернуть оси
относительно начала координат на 45 градусов, то
можно достичь ясного представления о нагрузках,
определяющих переменные: удовлетворенность на
работе и дома. </p>

<p><b>Методы вращения.</b> Существуют различные
методы вращения факторов. Целью этих методов
является получение понятной (интерпретируемой)
матрицы нагрузок, то есть факторов, которые ясно
отмечены высокими нагрузками для некоторых
переменных и низкими - для других. Эту общую
модель иногда называют <i>простой структурой </i>(более
формальное определение можно найти в
стандартных учебниках). Типичными методами
вращения являются стратегии <i>варимакс</i>, <i>квартимакс</i>,
и <i>эквимакс</i>. </p>

<p>Идея вращения по методу варимакс была описана
выше (см. <a href="stfacan.html#basic"><i>Выделение главных
компонент</i></a>), и этот метод можно применить
успешно и к рассматриваемой задаче. Как и ранее,
вы хотите найти вращение, максимизирующее
дисперсию по новым осям; другими словами, вы
хотите получить матрицу нагрузок на каждый
фактор таким образом, чтобы они отличались
максимально возможным образом и имелась
возможность их простой интерпретации. Ниже
приведена таблица нагрузок на повернутые
факторы. </p>

<table BORDER="1">
  <tr>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">STATISTICA<br>
    ФАКТОРНЫЙ<br>
    АНАЛИЗ</font></th>
    <th ALIGN="CENTER" COLSPAN="2"><font COLOR="BLUE" SIZE="2">Факторные
    нагрузки (Варимакс нормализ.)<br>
    Выделение: Главные компоненты<br>
    &nbsp;</font></th>
  </tr>
  <tr>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">Переменная</font></th>
    <th ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">Фактор 1</font></th>
    <th ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">Фактор 2</font></th>
  </tr>
  <tr>
    <td ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">РАБОТА_1<br>
    РАБОТА_2<br>
    РАБОТА_3<br>
    ДОМ_1<br>
    ДОМ_2<br>
    ДОМ_3</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.862443<br>
    .890267<br>
    .886055<br>
    .062145<br>
    .107230<br>
    .140876</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.051643<br>
    .110351<br>
    .152603<br>
    .845786<br>
    .902913<br>
    .869995</font></td>
  </tr>
  <tr>
    <td ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">Общая дисперсия<br>
    Доля общей дисп.</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">2.356684<br>
    .392781</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">2.325629<br>
    .387605</font></td>
  </tr>
</table>

<p><br CLEAR="ALL">
</p>

<p><b>Интерпретация факторной структуры. </b>Теперь
картина становится более ясной. Как и ожидалось,
первый фактор отмечен высокими нагрузками на
переменные, связанные с удовлетворенностью на
работе, а второй фактор - с удовлетворенностью
домом. Из этого вы должны заключить, что
удовлетворенность, измеренная вашим
вопросником, составлена из двух частей:
удовлетворенность домом и работой,
следовательно, вы произвели <i>классификацию</i>
переменных.</p>

<p>Рассмотрим следующий пример, здесь к
предыдущему примеру добавились четыре новых
переменных <em>Хобби</em>. </p>

<p><img BORDER="0" SRC="../graphics/an_factor.gif" alt="Трехмерный график" WIDTH="330" HEIGHT="239"></p>

<p>На этом графике факторных нагрузок 10
переменных были сведены к трем факторам - фактор
удовлетворенности работой (work), фактор
удовлетворенности домом (home), и фактор
удовлетворенности хобби (hobby/misc). Заметим, что
факторные нагрузки для каждого фактора имеют
сильно различающиеся значения для остальных
двух факторов, но большие значения именно для
этого фактора. Например, факторные нагрузки для
переменных, относящихся к хобби (выделены
зеленым цветом) имеют и большие, и малые значения
для&nbsp; &quot;дома&quot; и &quot;работы&quot;, но все четыре
переменные имеют большие факторные нагрузки для
фактора &quot;хобби&quot;. </p>

<p><b>Косоугольные факторы. </b>Некоторые авторы
(например, Харман (Harman, 1976), Дженнрих и Сэмпсон
(Jennrich, Sampson, 1966); Кларксон и Дженнрих (Clarkson, Jennrich,
1988)) обсуждали довольно подробно концепцию <i>косоугольных
</i>(не ортогональных) факторов, для того чтобы
достичь более простой интерпретации решений. В
частности, были развиты вычислительные
стратегии, как для вращения факторов, так и для
лучшего представления &quot;кластеров&quot;
переменных без отказа от ортогональности (т.е.
независимости) факторов. Однако косоугольные
факторы, получаемые с помощью этих процедур,
трудно интерпретировать. Возвратимся к примеру,
обсуждавшемуся выше, и предположим, что вы
включили в вопросник четыре пункта, измеряющих
другие типы удовлетворенности (<em>Хобби</em>).
Предположим, что ответы людей на эти пункты были
одинаково связаны как с удовлетворенностью
домом (<i>Фактор</i> <i>1</i>), так и работой (<i>Фактор 2</i>).
Косоугольное вращение должно дать, очевидно, два
коррелирующих фактора с меньшей, чем ранее,
выразительностью, то есть с большими
перекрестными нагрузками. </p>

<p><b>Иерархический факторный анализ. </b>Вместо
вычисления нагрузок косоугольных факторов, для
которых часто трудно дать хорошую интерпретацию,
вы можете использовать стратегию, впервые
предложенную Томсоном (Thompson, 1951) и Шмидтом и
Лейманом (Schmidt, Leiman, 1957), которая было подробно
развита и популяризирована Верри (Wherry, 1959, 1975, 1984).
В соответствии с этой стратегией, вначале
определяются кластеры и происходит вращение
осей в пределах кластеров, а затем вычисляются
корреляции между найденными (<i>косоугольными</i>)
факторами. Полученная корреляционная матрица
для косоугольных факторов затем подвергается
дальнейшему анализу для того, чтобы выделить
множество ортогональных факторов, разделяющих
изменчивость в переменных на ту, что относятся к
распределенной или общей дисперсии (вторичные
факторы), и на частные дисперсии, относящиеся к
кластерам или схожим переменным (пунктам
вопросника) в анализе (первичные факторы).
Применительно к рассматриваемому примеру такой
иерархический анализ может дать следующие
факторные нагрузки: </p>

<table BORDER="1">
  <tr>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">STATISTICA<br>
    ФАКТОРНЫЙ<br>
    АНАЛИЗ</font></th>
    <th ALIGN="CENTER" COLSPAN="3"><font COLOR="BLUE" SIZE="2">Вторичные и
    первичные факторные нагрузки<br>
    &nbsp;<br>
    &nbsp;</font></th>
  </tr>
  <tr>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">Фактор</font></th>
    <th ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">Вторич. 1</font></th>
    <th ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">Первич. 1</font></th>
    <th ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">Первич. 2</font></th>
  </tr>
  <tr>
    <td ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">РАБОТА_1<br>
    РАБОТА_2<br>
    РАБОТА_3<br>
    ДОМ_1<br>
    ДОМ_2<br>
    ДОМ_3<br>
    ХОББИ_1<br>
    ХОББИ_2<br>
    ХОББИ_3<br>
    ХОББИ_4</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.483178<br>
    .570953<br>
    .565624<br>
    .535812<br>
    .615403<br>
    .586405<br>
    .780488<br>
    .734854<br>
    .776013<br>
    .714183</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.649499<br>
    .687056<br>
    .656790<br>
    .117278<br>
    .079910<br>
    .065512<br>
    .466823<br>
    .464779<br>
    .439010<br>
    .455157</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.187074<br>
    .140627<br>
    .115461<br>
    .630076 <br>
    .668880<br>
    .626730<br>
    .280141<br>
    .238512<br>
    .303672<br>
    .228351</font></td>
  </tr>
</table>

<p><br CLEAR="ALL">
</p>

<p>Внимательное изучение позволяет сделать
следующие заключения: 

<ol>
  <li>Имеется общий (вторичный) фактор
    удовлетворенности, которому, по-видимому,
    подвержены все типы удовлетворенности,
    измеренные для 10 пунктов; </li>
  <li>Имеются вероятно две первичные уникальных
    области удовлетворения, которые могут быть
    описаны как удовлетворенностью работой, так и
    удовлетворенностью домашней жизнью. </li>
</ol>

<p>Верри (Wherry, 1984) обсудил подробно примеры такого
иерархического анализа и объяснил, каким образом
могут быть получены значимые и интерпретируемые
вторичные факторы. </p>

<p><b>Подтверждающий факторный анализ. </b>Последние
15 лет так называемые методы подтверждения имели
все большую популярность (например, см. Joreskog, Sorbom,
1979). Можно <i>априори</i> выбрать набор факторных
нагрузок для некоторого числа ортогональных или
косоугольных факторов, а затем проверить, может
ли быть наблюдаемая корреляционная матрица
воспроизведена при этом выборе. Подтверждающий
факторный анализ может быть проведен с помощью <a href="stsepath.html"><i>Моделирования структурными
уравнениями (SEPATH)</i></a>. </p>

<table ALIGN="RIGHT">
  <tr>
    <td><font size="1"><a HREF="stfacan.html#index">В начало</a></font> </td>
  </tr>
</table>

<p><br CLEAR="RIGHT">
<a NAME="sundries"></a> </p>

<p><font SIZE="4" COLOR="navy">Другие результаты и статистики </font></p>

<p><b>Значения факторов.</b> Вы можете оценить
действительные значения факторов для отдельных
наблюдений. Эти значения используются, когда
желают провести дальнейший анализ факторов. </p>

<p><b>Воспроизведенные и остаточные корреляции. </b>Дополнительным
способом проверки числа выделенных факторов
является вычисление корреляционной матрицы,
которая близка исходной, если факторы выделены
правильно. Эта матрица называется <i>воспроизведенной</i>
корреляционной матрицей. Для того чтобы увидеть,
как эта матрица отклоняется от исходной
корреляционной матрицы (с которой начинался
анализ), можно вычислить разность между ними.
Полученная матрица называется матрицей <i>остаточных
</i>корреляций. Остаточная матрица может указать
на &quot;несогласие&quot;, т.е. на то, что
рассматриваемые коэффициенты корреляции не
могут быть получены с достаточной точностью на
основе имеющихся факторов. </p>

<p><b>Плохо обусловленные матрицы. </b>Если имеются
избыточные переменные, то нельзя вычислить
обратную матрицу. Например, если переменная
является суммой двух других переменных,
отобранных для этого анализа, то корреляционная
матрица для такого набора переменных не может
быть обращена, и факторный анализ принципиально
не может быть выполнен. На практике это
происходит, когда вы пытаетесь применить
факторный анализ к множеству сильно
коррелированных (зависимых) переменных, что
иногда случается, например, в исследованиях
вопросников. Тогда вы можете искусственно
понизить все корреляции в матрице путем
добавления малой константы к диагональным
элементам матрицы, и затем стандартизировать ее.
Эта процедура обычно приводит к матрице, которая
может быть обращена, и поэтому к ней применим
факторный анализ; более того, эта процедура не
влияет на набор факторов. Однако оценки
оказываются менее точными. </p>

<table BORDER="1">
  <tr>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">STATISTICA<br>
    ФАКТОРНЫЙ<br>
    АНАЛИЗ</font></th>
    <th ALIGN="CENTER" COLSPAN="3"><font COLOR="BLUE" SIZE="2">Вторичные и
    первичные факторные нагрузки<br>
    &nbsp;<br>
    &nbsp;</font></th>
  </tr>
  <tr>
    <th ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">Фактор</font></th>
    <th ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">Вторич. 1</font></th>
    <th ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">Первич. 1</font></th>
    <th ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">Первич. 2</font></th>
  </tr>
  <tr>
    <td ALIGN="LEFT"><font COLOR="BLUE" SIZE="2">РАБОТА_1<br>
    РАБОТА_2<br>
    РАБОТА_3<br>
    ДОМ_1<br>
    ДОМ_2<br>
    ДОМ_3<br>
    ХОББИ_1<br>
    ХОББИ_2<br>
    ХОББИ_3<br>
    ХОББИ_4</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.483178<br>
    .570953<br>
    .565624<br>
    .535812<br>
    .615403<br>
    .586405<br>
    .780488<br>
    .734854<br>
    .776013<br>
    .714183</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.649499<br>
    .687056<br>
    .656790<br>
    .117278<br>
    .079910<br>
    .065512<br>
    .466823<br>
    .464779<br>
    .439010<br>
    .455157</font></td>
    <td ALIGN="RIGHT"><font COLOR="BLUE" SIZE="2">.187074<br>
    .140627<br>
    .115461<br>
    .630076 <br>
    .668880<br>
    .626730<br>
    .280141<br>
    .238512<br>
    .303672<br>
    .228351</font></td>
  </tr>
</table>

<p><br CLEAR="ALL">
</p>

<p>Внимательное изучение позволяет сделать
следующие заключения: 

<ol>
  <li>Имеется общий (вторичный) фактор
    удовлетворенности, которому, по-видимому,
    подвержены все типы удовлетворенности,
    измеренные для 10 пунктов; </li>
  <li>Имеются вероятно две первичные уникальных
    области удовлетворения, которые могут быть
    описаны как удовлетворенностью работой, так и
    удовлетворенностью домашней жизнью. </li>
</ol>

<p>Верри (Wherry, 1984) обсудил подробно примеры такого
иерархического анализа и объяснил, каким образом
могут быть получены значимые и интерпретируемые
вторичные факторы.</p>

<table ALIGN="RIGHT">
  <tr>
    <td><font size="1"><a HREF="stfacan.html#index">В начало</a></font> </td>
  </tr>
</table>

<p><br CLEAR="RIGHT">
<br>
<br>
</p>

<hr SIZE="1">

<p align="center"><br>
<img SRC="../stathoms.jpg" ALIGN="LEFT" WIDTH="151" HEIGHT="47"> <br CLEAR="ALL">
<font size="1">(c) Copyright StatSoft, Inc., 1984-2001<br>
STATISTICA является торговой маркой StatSoft, Inc. </font></p>

<hr SIZE="1">
</body>
</html>
