<html>

<head>
<title>Дисперсионный анализ</title>
</head>

<body BACKGROUND="../tile1.gif">
<font SIZE="5" COLOR="AA0000"><b>

<p align="center">Дисперсионный анализ</b></font></p>

<hr SIZE="1">

<p><a NAME="index"></a> 

<ul>
  <li><a HREF="stanman.html#basic">Основные идеи</a> <ul>
      <li><a HREF="stanman.html#bthe">Разбиение суммы квадратов</a> </li>
      <li><a HREF="stanman.html#bmulti">Многофакторный дисперсионный
        анализ</a> </li>
      <li><a HREF="stanman.html#binteraction">Эффекты взаимодействия</a> </li>
    </ul>
  </li>
  <li><a HREF="stanman.html#complex">Сложные планы</a> <ul>
      <li><a HREF="stanman.html#cbetween">Межгрупповые планы и планы
        повторных измерений</a> </li>
      <li><a HREF="stanman.html#cincomplete">Неполные (гнездовые) планы</a> </li>
    </ul>
  </li>
  <li><a HREF="stanman.html#analysis">Ковариационный анализ (ANCOVA)</a> <ul>
      <li><a HREF="stanman.html#afixed">Фиксированные ковариаты</a> </li>
      <li><a HREF="stanman.html#achanging">Переменные ковариаты</a> </li>
    </ul>
  </li>
  <li><a HREF="stanman.html#multivariate">Многомерные планы:
    многомерный дисперсионный и ковариационный
    анализ</a> <ul>
      <li><a HREF="stanman.html#mbetween">Межгрупповые планы</a> </li>
      <li><a HREF="stanman.html#mrepeated">Планы с повторными
        измерениями</a> </li>
      <li><a HREF="stanman.html#msum">Суммы значений переменной и
        дисперсионного анализа</a> </li>
    </ul>
  </li>
  <li><a HREF="stanman.html#contrast">Анализ контрастов и
    апостериорные критерии</a> <ul>
      <li><a HREF="stanman.html#pwhy">Почему сравниваютсяотдельные
        множества средних?</a> </li>
      <li><a HREF="stanman.html#pcontrast">Анализ контрастов</a> </li>
      <li><a HREF="stanman.html#ppost">Апостериорные критерии</a> </li>
    </ul>
  </li>
  <li><a HREF="stanman.html#assumptions">Предположения и эффекты их
    нарушения</a> <ul>
      <li><a HREF="stanman.html#deviation">Нормальность распределения</a>
      </li>
      <li><a HREF="stanman.html#homogeneity">Однородность дисперсии</a> </li>
      <li><a HREF="stanman.html#2">Однородность дисперсии и
        ковариации</a> </li>
      <li><a HREF="stanman.html#sphericity">Сферичность и сложная
        симметрия</a> </li>
    </ul>
  </li>
  <li><a HREF="stanman.html#methods">Методы дисперсионного анализа</a>
  </li>
</ul>

<hr SIZE="1">

<p>Этот раздел содержит вводный обзор и
обсуждение некоторых методов дисперсионного
анализа, включая планы с повторными измерениями,
ковариационный анализ, многомерный
дисперсионный анализ, несбалансированные и
вложенные планы, эффекты контрастов,
апостериорные сравнения и др. Дополнительно,
можно обратиться к разделу <a HREF="stvarcom.html">Компоненты
дисперсии</a> (разделы связанные с оцениванием
компонент дисперсии в смешанных планах), <a HREF="stexdes.html">Планирование эксперимента</a> (разделы
связанные со специальными областями применения
дисперсионного анализа в промышленных условиях),
а также <a HREF="stprocan.html">Анализ повторяемости и
воспроизводимости</a> (разделы, относящиеся к
оцениванию надежности и точности измерительных
систем).</p>

<hr SIZE="1">

<p><a NAME="basic"></a></p>
<font SIZE="5" COLOR="navy">

<p>Основные идеи</font></p>

<p><font size="4" color="navy">Цель дисперсионного анализа.</font></p>

<p align="left">Основной целью дисперсионного анализа
является исследование значимости различия между
средними. Раздел <a href="../esc.html"><i>Элементарные
понятия статистики</i></a> содержит краткое
введение в исследование статистической
значимости. Если вы просто сравниваете средние в
двух выборках, дисперсионный анализ даст тот же
результат, что и обычный <a href="stbasic.html#t-test for independent samples"><i>t-</i>критерий для
независимых выборок</a> (если сравниваются две
независимые группы объектов или наблюдений) или <a href="stbasic.html#t-test for dependent samples"><i>t</i>-критерий для
зависимых выборок</a> (если сравниваются две
переменные на одном и том же множестве объектов
или наблюдений). Если вы не достаточно знакомы с
этими критериями, рекомендуем обратиться к
разделу <a href="stbasic.html"><i>Основные статистики и
таблицы</i></a>. </p>
<b>

<p>Откуда произошло название <i>Дисперсионный
анализ</i>?<i> </i></b>Может показаться странным, что
процедура сравнения средних называется
дисперсионным анализом. В действительности, это
связано с тем, что при исследовании
статистической значимости различия между
средними двух (или нескольких) групп, мы на самом
деле сравниваем (т.е. анализируем) выборочные
дисперсии. Фундаментальная концепция
дисперсионного анализа предложена Фишером в 1920
году. Возможно, более естественным был бы термин
анализ суммы квадратов или анализ вариации, но в
силу традиции употребляется термин
дисперсионный анализ. 

<ul>
  <li><a HREF="stanman.html#bthe">Разбиение суммы квадратов</a> </li>
  <li><a HREF="stanman.html#bmulti">Многофакторный дисперсионный
    анализ</a> </li>
  <li><a HREF="stanman.html#binteraction">Эффекты взаимодействия</a> </li>
</ul>

<p>Также смотрите разделы. 

<ul>
  <li><a HREF="stanman.html#complex">Сложные планы</a> </li>
  <li><a HREF="stanman.html#analysis">Ковариационный анализ (ANCOVA)</a> </li>
  <li><a HREF="stanman.html#multivariate">Многомерные планы:
    многомерный дисперсионный и ковариационный
    анализ</a> </li>
  <li><a HREF="stanman.html#contrast">Анализ контрастов и
    апостериорные критерии</a> </li>
  <li><a HREF="stanman.html#assumptions">Предположения и эффекты их
    нарушения</a> </li>
</ul>

<p>См. также <a HREF="stanman.html#methods">Методы
дисперсионного анализа</a>, <a HREF="stvarcom.html">Компоненты
дисперсии и смешанная модель ANOVA/ANCOVA</a>, а также <a HREF="stexdes.html">Планироване эксперимента</a>. </p>

<p><a NAME="bthe"></a><font size="4" color="navy">Разбиение суммы
квадратов</font></p>

<p>Для выборки объема n выборочная дисперсия
вычисляется как сумма квадратов отклонений от
выборочного среднего, деленная на <i>n-1</i> (объем
выборки минус единица). Таким образом, при
фиксированном объеме выборки n дисперсия есть
функция суммы квадратов (отклонений),
обозначаемая, для краткости, <i>SS</i> (от
английского Sum of Squares - Сумма квадратов). Далее
слово выборочная мы часто опускаем, прекрасно
понимая, что рассматривается выборочная
дисперсия или оценка дисперсии. В основе
дисперсионного анализа лежит разделение
дисперсии на части или компоненты. Рассмотрим
следующий набор данных:</p>

<table BORDER="1">
  <tr>
    <th>&nbsp;</th>
    <th ALIGN="LEFT"><font SIZE="2" COLOR="BLUE">Группа 1</font></th>
    <th ALIGN="LEFT"><font SIZE="2" COLOR="BLUE">Группа 2</font></th>
  </tr>
  <tr>
    <th ALIGN="LEFT"><font SIZE="2" COLOR="BLUE">Наблюдение 1<br>
    Наблюдение 2<br>
    Наблюдение 3</font></th>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">2<br>
    3<br>
    1</font></td>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">6<br>
    7<br>
    5</font></td>
  </tr>
  <tr>
    <th ALIGN="LEFT"><font SIZE="2" COLOR="BLUE">Среднее<br>
    Сумма квадратов (СК)</font></th>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">2<br>
    2</font></td>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">6<br>
    2</font></td>
  </tr>
  <tr>
    <th ALIGN="LEFT"><font SIZE="2" COLOR="BLUE">Общее среднее<br>
    Общая сумма квадратов</font></th>
    <td ALIGN="CENTER" COLSPAN="2"><font SIZE="2" COLOR="BLUE">&nbsp;4<br>
    28</font></td>
  </tr>
</table>

<p>Средние двух групп существенно различны (<i>2 </i>и
<i>6 </i>соответственно). Сумма квадратов отклонений
<i>внутри</i> каждой группы равна <i>2</i>. Складывая
их, получаем 4. Если теперь повторить эти
вычисления <i>без учета</i> групповой
принадлежности, то есть, если вычислить <i>SS</i>
исходя из общего среднего этих двух выборок, то
получим величину <i>28</i>. Иными словами, дисперсия
(сумма квадратов), основанная на внутригрупповой
изменчивости, приводит к гораздо меньшим
значениям, чем при вычислении на основе общей
изменчивости (относительно общего среднего).
Причина этого, очевидно, заключается в
существенной разнице между средними значениями,
и это различие между средними и объясняет
существующее различие между суммами квадратов. В
самом деле, если использовать для анализа этих
данных модуль <i>Дисперсионный анализ</i>, то будет
получена следующая таблица, называемая таблицей
дисперсионного анализа: </p>

<table BORDER="1">
  <tr>
    <th ROWSPAN="2" ALIGN="TOP">&nbsp;</th>
    <th COLSPAN="5" ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">ГЛАВНЫЙ ЭФФЕКТ </font></th>
  </tr>
  <tr>
    <th ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">SS</font></th>
    <th ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">ст.св.&nbsp;</font></th>
    <th ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">MS</font></th>
    <th ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">F</font></th>
    <th ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">p</font></th>
  </tr>
  <tr>
    <th ALIGN="LEFT"><font SIZE="2" COLOR="BLUE">Эффект<br>
    Ошибка</font></th>
    <td ALIGN="RIGHT"><font SIZE="2" COLOR="BLUE">24.0<br>
    4.0</font></td>
    <td ALIGN="RIGHT"><font SIZE="2" COLOR="BLUE">1<br>
    4</font></td>
    <td ALIGN="RIGHT"><font SIZE="2" COLOR="BLUE">24.0<br>
    1.0</font></td>
    <td ALIGN="RIGHT"><font SIZE="2" COLOR="BLUE">24.0<br>
    &nbsp;</font></td>
    <td ALIGN="RIGHT"><font SIZE="2" COLOR="BLUE">.008<br>
    &nbsp;</font></td>
  </tr>
</table>

<p><br clear="all">
Как видно из таблицы, общая сумма квадратов <i>SS </i>=<i>
</i>28 разбита на компоненты: сумму квадратов,
обусловленную <i>внутригрупповой</i>
изменчивостью (<i>2+2=4</i>; см. вторую строку таблицы)
и сумму квадратов, обусловленную различием
средних значений между группами (28-(2+2)=24; см
первую строку таблицы). Заметим, что <i>MS </i>в этой
таблице есть средний квадрат, равный <i>SS, </i>деленная
на число степеней свободы (ст.св).</p>
<b><i>

<p>SS</i> ошибок и <i>SS</i> эффекта.</b> Внутригрупповая
изменчивость (<i>SS</i>) обычно называется
остаточной компонентой или дисперсией <i>ошибки.</i>
Это означает, что обычно при проведении
эксперимента она не может быть предсказана или
объяснена. С другой стороны, <i>SS</i> <i>эффекта</i>
(или компоненту дисперсии между группами) можно
объяснить различием между средними значениями в
группах. Иными словами, принадлежность к
некоторой группе <i>объясняет </i>межгрупповую
изменчивость, т.к. нам известно, что эти группы
обладают разными средними значениями.</p>
<b>

<p>Проверка значимости. </b>Основные идеи проверки
статистической значимости обсуждаются в разделе
<a href="../esc.html"><i>Элементарные понятия статистики</i></a>.
В этом же разделе объясняются причины, по которым
многие критерии используют отношение
объясненной и необъясненной дисперсии. Примером
такого использования является сам дисперсионный
анализ. Проверка значимости в дисперсионном
анализе основана на сравнении компоненты
дисперсии, обусловленной межгрупповым разбросом
(называемой <i>средним квадратом эффекта</i> или <i>MS<font SIZE="1">эффект</font></i>) и компоненты дисперсии,
обусловленной внутригрупповым разбросом
(называемой <i>средним квадратом ошибки</i> или <i>MS<font SIZE="1">ошибка</font></i>; эти термины были впервые
использованы в работе Edgeworth, 1885). Если верна
нулевая гипотеза (равенство средних в двух
популяциях), то можно ожидать сравнительно
небольшое различие выборочных средних из-за
чисто случайной изменчивости. Поэтому, при
нулевой гипотезе, внутригрупповая дисперсия
будет практически совпадать с общей дисперсией,
подсчитанной без учета групповой
принадлежности. Полученные внутригрупповые
дисперсии можно сравнить с помощью <a HREF="../glossary/gloss_f.html#F Distribution">F-критерия</a>,
проверяющего, действительно ли отношение
дисперсий значимо больше 1. В рассмотренном выше
примере <i>F-</i>критерий показывает, что различие
между средними статистически значимо (значимо на
уровне 0.008).</p>
<b>

<p>Основная логика дисперсионного анализа.</b>
Подводя итоги, можно сказать, что целью
дисперсионного анализа является проверка
статистической значимости различия между
средними (для групп или переменных). Эта проверка
проводится с помощью разбиения суммы квадратов
на компоненты, т.е. с помощью разбиения общей
дисперсии (вариации) на части, одна из которых
обусловлена случайной ошибкой (то есть
внутригрупповой изменчивостью), а вторая связана
с различием средних значений. Последняя
компонента дисперсии затем используется для
анализа статистической значимости различия
между средними значениями. Если это различие <i>значимо</i>,
нулевая гипотеза <i>отвергается</i> и принимается
альтернативная гипотеза о существовании
различия между средними. </p>
<b>

<p>Зависимые и независимые переменные. </b>Переменные,
значения которых определяется с помощью
измерений в ходе эксперимента (например, балл,
набранный при тестировании), называются <i>зависимыми</i>
переменными. Переменные, которыми можно
управлять при проведении эксперимента (например,
методы обучения или другие критерии, позволяющие
разделить наблюдения на группы или
классифицировать) называются <i>факторами</i> или <i>независимыми</i>
переменными. Более подробно эти понятия описаны
в разделе <a href="../esc.html"><i>Элементарные понятия
статистики</i></a>.</p>

<p><font size="4"><a name="bmulti"></a><font color="navy">Многофакторный
дисперсионный анализ</font></font><b></p>

<p></b>В рассмотренном выше простом примере вы
могли бы сразу вычислить <a href="stbasic.html#t-test for independent samples"><i>t-</i>критерий для
независимых выборок</a>, используя
соответствующую опцию модуля <i>Основные
статистики и таблицы.</i> Полученные результаты,
естественно, совпадут с результатами
дисперсионного анализа. Однако дисперсионный
анализ содержит гораздо более гибкие и мощные
технические средства, позволяющие исследовать
планы практически неограниченной сложности.</p>

<p><b>Множество факторов.</b> Мир по своей природе
сложен и многомерен. Ситуации, когда некоторое
явление полностью описывается одной переменной,
чрезвычайно редки. Например, если мы пытаемся
научиться выращивать большие помидоры, следует
рассматривать факторы, связанные с генетической
структурой растений, типом почвы, освещенностью,
температурой и т.д. Таким образом, при проведении
типичного эксперимента приходится иметь дело с
большим количеством факторов. Основная причина,
по которой использование дисперсионного анализа
предпочтительнее повторного сравнения двух
выборок при разных уровнях факторов с помощью
серий <i>t-</i>критерия, заключается в том, что
дисперсионный анализ существенно более <i>эффективен</i>
и, для малых выборок, более информативен. Вам
нужно сделать определенные усилия, чтобы
овладеть техникой дисперсионного анализа,
реализованной на STATISTICA, и ощутить все ее
преимущества в конкретных исследованиях.</p>
<b>

<p>Управление факторами. </b>Предположим, что в
рассмотренном выше примере анализа двух выборок
мы добавим еще один фактор, например, <i>Пол </i>- <i>Gender</i>.
Пусть каждая группа теперь состоит из 3 мужчин и 3
женщин. План этого эксперимента можно
представить в виде таблицы 2 на 2: </p>

<table BORDER="1">
  <tr>
    <th WIDTH="80">&nbsp;</th>
    <th ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">Экспериментальная<br>
    группа 1</font></th>
    <th ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">Экспериментальная<br>
    группа 2</font></th>
  </tr>
  <tr>
    <th ALIGN="LEFT"><font SIZE="2" COLOR="BLUE">Мужчины<br>
    &nbsp;<br>
    &nbsp;</font></th>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">2<br>
    3<br>
    1</font></td>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">6<br>
    7<br>
    5</font></td>
  </tr>
  <tr>
    <th ALIGN="RIGHT"><font SIZE="2" COLOR="BLUE">Среднее</font></th>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">2</font></td>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">6</font></td>
  </tr>
  <tr>
    <th ALIGN="LEFT"><font SIZE="2" COLOR="BLUE">Женщины<br>
    &nbsp;<br>
    &nbsp;</font></th>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">4<br>
    5<br>
    3</font></td>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">8<br>
    9<br>
    7</font></td>
  </tr>
  <tr>
    <th ALIGN="RIGHT"><font SIZE="2" COLOR="BLUE">Среднее</font></th>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">4</font></td>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">8</font></td>
  </tr>
</table>

<p>До проведения вычислений можно заметить, что в
этом примере общая дисперсия имеет, по крайней
мере, три источника: (1) случайная ошибка
(внутригрупповая дисперсия), (2) изменчивость,
связанная с принадлежностью к экспериментальной
группе, и (3) изменчивость, обусловленная полом
объектов наблюдения. (Отметим, что существует еще
один возможный источник изменчивости -<i>
взаимодействие факторов</i>, который мы обсудим
позднее). Что произойдет, если мы не будем
включать <i>пол</i> как фактор при проведении
анализа и вычислим обычный <i>t</i>-критерий? Если мы
будем вычислять суммы квадратов, игнорируя <i>пол </i>(т.е.
объединяя объекты разного пола в одну группу при
вычислении внутригрупповой дисперсии и получив
при этом сумму квадратов для каждой группы
равную <i>SS</i> =10 и общую сумму квадратов <i>SS </i>= 10+10 =
20), то получим большее значение внутригрупповая
дисперсии, чем при более точном анализе с
дополнительным разбиением на подгруппы по <i>полу</i>
(при этом внутригрупповые средние будут равны 2, а
общая внутригрупповая сумма квадратов равна <i>SS =
</i>2+2+2+2 = 8). </p>

<p>Итак, при введении дополнительного фактора: <i>пол</i>,
остаточная дисперсия уменьшилась. Это связано с
тем, что среднее значение для <i>мужчин</i> меньше,
чем среднее значение для <i>женщин</i>, и это
различие в средних значениях увеличивает
суммарную внутригрупповую изменчивость, если
фактор пола не учитывается. Управление
дисперсией ошибки увеличивает чувствительность
(мощность) критерия. На этом примере видно еще
одно преимущество дисперсионного анализа по
сравнению с обычным <i>t</i>-критерием для двух
выборок. Дисперсионный анализ позволяет изучать
каждый фактор, управляя значениями других
факторов. Это, в действительности, и является
основной причиной его большей статистической
мощности (для получения значимых результатов
требуются меньшие объемы выборок). По этой
причине дисперсионный анализ даже на небольших
выборках дает статистически более значимые
результаты, чем простой <i>t-</i>критерий.</p>

<p><font size="4" color="navy">Эффекты взаимодействия</font><a NAME="binteraction"></a></p>

<p>Существует еще одно преимущество
дисперсионного анализа перед обычным <i>t</i>-критерием:
дисперсионный анализ позволяет обнаружить
эффекты <i>взаимодействия </i>между факторами и,
поэтому, позволяет проверять более сложные
гипотезы. Рассмотрим еще один пример,
иллюстрирующий только что сказанное. (Термин <i>взаимодействие
</i>впервые был использован Фишером в работе Fisher,
1926)</p>

<p><b>Главные эффекты, попарные (двухфакторные)
взаимодействия. </b>Предположим, что имеется две
группы студентов, причем психологически
студенты первой группы настроены на выполнение
поставленных задач и более целеустремленны, чем
студенты второй группы, состоящей из более
ленивых студентов. Разобьем каждую группу
случайным образом пополам и предложим одной
половине в каждой группе сложное задание, а
другой - легкое. После этого измерим, насколько
напряженно студенты работают над этими
заданиями. Средние значения для этого
(вымышленного) исследования показаны в таблице:</p>

<table BORDER="1">
  <tr>
    <th>&nbsp;</th>
    <th ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">Целеустремленные</font></th>
    <th ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">&nbsp;&nbsp;&nbsp;&nbsp; Ленивые
    &nbsp;&nbsp;&nbsp;&nbsp; </font></th>
  </tr>
  <tr>
    <th ALIGN="RIGHT"><font SIZE="2" COLOR="BLUE">Трудное задание<br>
    Легкое задание</font></th>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">10<br>
    5</font></td>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">5<br>
    10</font></td>
  </tr>
</table>

<p>Какой вывод можно сделать из этих результатов?
Можно ли заключить, что: (1) над сложным заданием
студенты трудятся более напряженно; (2)
честолюбивые студенты работают упорнее, чем
ленивые? Ни одно из этих утверждений не отражает
сущность систематического характера средних,
приведенных в таблице. Анализируя результаты,
правильнее было бы сказать, что над сложными
заданиями работают упорнее только честолюбивые
студенты, в то время как над легкими заданиями
только ленивые работают упорнее. Другими словами
характер студентов и сложность задания <i>взаимодействуя</i>
между собой влияют на затрачиваемое усилие. Это
является примером <i>попарного взаимодействия</i>
между характером студентов и сложностью задания.
Заметим, что утверждения 1 и 2 описывают <i>главные
эффекты</i>. </p>
<b>

<p>Взаимодействия высших порядков. </b>В то время
как объяснить попарные взаимодействия еще
сравнительно легко, <a HREF="../glossary/gloss_v.html#Interactions">взаимодействия</a>
высших порядков объяснить значительно сложнее.
Представьте, что в рассматриваемый выше пример,
введен еще один фактор <i>пол </i>и получена
следующая таблица средних значений:</p>

<table BORDER="1">
  <tr>
    <th ALIGN="LEFT"><font SIZE="2" COLOR="BLUE">Женщины&nbsp;</font></th>
    <th ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">Целеустремленные</font></th>
    <th ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">&nbsp;&nbsp;&nbsp;&nbsp; Ленивые
    &nbsp;&nbsp;&nbsp;&nbsp; </font></th>
  </tr>
  <tr>
    <th ALIGN="RIGHT"><font SIZE="2" COLOR="BLUE">Трудное задание<br>
    Легкое задание</font></th>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">10<br>
    5</font></td>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">5<br>
    10</font></td>
  </tr>
  <tr>
    <th ALIGN="LEFT"><font SIZE="2" COLOR="BLUE">Мужчины&nbsp;</font></th>
    <th ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">Целеустремленные</font></th>
    <th ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">&nbsp;&nbsp;&nbsp;&nbsp; Ленивые
    &nbsp;&nbsp;&nbsp;&nbsp; </font></th>
  </tr>
  <tr>
    <th ALIGN="RIGHT"><font SIZE="2" COLOR="BLUE">Трудное задание<br>
    Легкое задание</font></th>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">1<br>
    6</font></td>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">6<br>
    1</font></td>
  </tr>
</table>

<p>Какие теперь выводы можно сделать из
полученных результатов? Графики средних
позволяют объяснять сложные эффекты. Модуль
дисперсионного анализа позволяет строить эти
графики практически одним щелчком мыши.
Изображение на этих графике внизу представляет
собой изучаемое трехфакторное взаимодействие.</p>

<p><img BORDER="0" SRC="../popups/popup8.gif" WIDTH="306" HEIGHT="218"></p>

<p>Глядя на график, можно сказать, что у женщин
существует взаимодействие между характером и
сложностью теста: целеустремленные женщины
работают над трудным заданием более напряженно,
чем над легким. У мужчин то же взаимодействие
носит обратный характер. Видно, что описание
взаимодействия между факторами становится более
запутанным. </p>
<b>

<p>Общий способ описания взаимодействий.</b> В
общем случае <a HREF="../glossary/gloss_v.html#Interactions">взаимодействие</a>
между факторами описывается в виде изменения
одного эффекта под воздействием другого. В
рассмотренном выше примере двухфакторное
взаимодействие можно описать как изменение
главного эффекта фактора, характеризующего
сложность задачи, под воздействием фактора,
описывающего характер студента. Для
взаимодействия трех факторов из предыдущего
параграфа можно сказать, что взаимодействие двух
факторов (сложности задачи и характера студента)
изменяется под воздействием <i>Пола.</i> Если
изучается взаимодействие четырех факторов,
можно сказать, что взаимодействие трех факторов,
изменяется под воздействием четвертого фактора,
т.е. существуют различные типы взаимодействий на
разных уровнях четвертого фактора. Оказалось,
что во многих областях взаимодействие пяти или
даже большего количества факторов не является
чем-то необычным.</p>

<p>&nbsp;</p>

<table ALIGN="RIGHT">
  <tr>
    <td><font SIZE="1"><a HREF="stanman.html#index">В начало</a></font></td>
  </tr>
</table>

<p><br>
</p>

<hr SIZE="1">

<p><a name="complex"></a><br CLEAR="ALL">
<font size="5" color="navy">Сложные планы</font></p>

<p>В этом разделе будет дан обзор основных
&quot;кирпичиков&quot;, из которых строятся сложные
планы. 

<ul>
  <li><a HREF="stanman.html#cbetween">Межгрупповые планы и планы
    повторных измерений</a> </li>
  <li><a HREF="stanman.html#cincomplete">Неполные (гнездовые) планы</a> </li>
</ul>

<p>Для просмотра других разделов <i>Вводного
обзора </i>выберите соответствующее название
ниже. 

<ul>
  <li><a HREF="stanman.html#basic">Основные идеи</a> </li>
  <li><a HREF="stanman.html#analysis">Ковариационный анализ (ANCOVA)</a> </li>
  <li><a HREF="stanman.html#multivariate">Многомерные планы:
    дисперсионный и ковариационный анализ</a> </li>
  <li><a HREF="stanman.html#contrast">Аналих контрастов и
    апостериорные критерии</a> </li>
  <li><a HREF="stanman.html#assumptions">Предположения и последствия
    их нарушения</a> </li>
</ul>

<p>См. также <a HREF="stanman.html#methods">Методы
дисперсионного анализа</a>, <a HREF="stvarcom.html">Компоненты
дисперсии и смешанные модели ANOVA/ANCOVA</a> и <a HREF="stexdes.html">Планирование экспермента</a>.</p>

<p><a NAME="cbetween"></a><font size="4" color="navy">Межгрупповые планы
и планы с повторными измерениями</font></p>

<p>При сравнении двух различных групп обычно
используется <a href="stbasic.html#t-test for independent samples">t-критерий
для независимых выборок</a> (из модуля <i>Основные
статистики и таблицы</i>). Когда сравниваются две
переменные на одном и том же множестве объектов
(наблюдений), используется <a href="stbasic.html%20#t-test for dependent samples"><i>t</i>-критерий для
зависимых выборок</a>. Для дисперсионного анализа
также важно зависимы или нет выборки. Если
имеются повторные измерения одних и тех же
переменных (при разных условиях или в разное
время) <i>для одних и тех же объектов</i>, то говорят
о наличии <i>фактора повторных измерений </i>(называемого
также <i>внутригрупповым фактором,</i> поскольку
для оценки его значимости вычисляется
внутригрупповая сумма квадратов). Если
сравниваются разные группы объектов (например,
мужчины и женщины, три штамма бактерий и т.п.), то
разница между группами описывается <i>межгрупповым
фактором. </i>Способы вычисления критериев
значимости для двух описанных типов факторов
различны, но общая их логика и интерпретации
совпадает.</p>
<b>

<p>Меж- и внутригрупповые планы. </b>Во многих
случаях эксперимент требует включение в план и
межгруппового фактора, и фактора повторных
измерений. Например, измеряются математические
навыки студентов женского и мужского пола (где <i>пол
</i>-межгрупповой фактор) в начале и в конце
семестра. Два измерения навыков<i> </i>каждого
студента образуют внутригрупповой фактор (или
фактор с повторными измерениями). Интерпретация
главных эффектов и <a href="../glossary/gloss_v.html#Interactions">взаимодействий</a>
для межгрупповых факторов и факторов повторных
измерений совпадает, и оба типа факторов могут,
очевидно, взаимодействовать между собой
(например, женщины приобретают навыки в течение
семестра, а мужчины их теряют). </p>

<p><a name="cincomplete"></a><font size="4" color="navy">Неполные
(гнездовые) планы</font></p>

<p>Во многих случаях можно пренебречь эффектом
взаимодействия. Это происходит или когда
известно, что в популяции эффект взаимодействия
отсутствует, или когда осуществление полного <i>факторного</i>
плана невозможно. Например, пусть изучается
влияние четырех добавок к топливу на расход
горючего. Выбираются четыре автомобиля и четыре
водителя. Полный <i>факторный</i> эксперимент
требует, чтобы каждая комбинация: добавка,
водитель, автомобиль - появились хотя бы один раз.
Для этого нужно не менее 4 x 4 x 4 = 64 групп испытаний,
что требует слишком больших временных затрат.
Кроме того, вряд ли существует взаимодействие
между водителем и добавкой к топливу. Принимая
это во внимание, можно использовать план типа <i>Латинские
квадраты, </i>в котором содержится лишь<i> </i>16 групп
испытаний (четыре добавки обозначаются буквами A,
B, C и D):</p>

<table BORDER="1">
  <tr>
    <th ROWSPAN="2">&nbsp;</th>
    <th ALIGN="CENTER" COLSPAN="4"><font SIZE="2" COLOR="BLUE">Автомобиль</font></th>
  </tr>
  <tr>
    <th><font SIZE="2" COLOR="BLUE">&nbsp;1&nbsp;</font></th>
    <th><font SIZE="2" COLOR="BLUE">&nbsp;2&nbsp;</font></th>
    <th><font SIZE="2" COLOR="BLUE">&nbsp;3&nbsp;</font></th>
    <th><font SIZE="2" COLOR="BLUE">&nbsp;4&nbsp;</font></th>
  </tr>
  <tr>
    <th ALIGN="LEFT"><font SIZE="2" COLOR="BLUE">Водитель 1<br>
    Водитель 2<br>
    Водитель 3<br>
    Водитель 4</font></th>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">A<br>
    B<br>
    C<br>
    D</font></td>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">B<br>
    C<br>
    D<br>
    A</font></td>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">C<br>
    D<br>
    A<br>
    B</font></td>
    <td ALIGN="CENTER"><font SIZE="2" COLOR="BLUE">D<br>
    A<br>
    B<br>
    C</font></td>
  </tr>
</table>

<p>Латинские квадраты описаны в большинстве книг
по планированию экспериментов (например, Hays, 1988;
Lindman, 1974; Milliken and Johnson, 1984; Winer, 1962), и здесь они не
будут детально обсуждаться. Отметим, что
латинские квадраты это <i>неnолные</i> планы, в
которых участвуют не все комбинации уровней
факторов. Например, водитель 1 управляет
автомобилем 1 только с добавкой А, водитель 3
управляет автомобилем 1 только с добавкой С.
Уровни фактора <i>добавки </i>(A, B, C и D) вложены в
ячейки таблицы <i>автомобиль </i>x<i> водитель </i>как
яйца в гнезда. Это мнемоническое правило полезно
для понимания природы <i>гнездовых</i> планов.
Модуль <i>Дисперсионный анализ</i> предоставляет
простые способы анализ планов такого типа. </p>

<p>Отметим, что анализ планов такого типа возможен
и в некоторых других модулях системы <i>STATISTICA</i>.
Подробнее см. в разделе <a href="stanman.html#methods">Методы
дисперсионного анализа</a>. В частности, модуль <a href="stvarcom.html">Компоненты дисперсии и смешанные
модели ANOVA/ANCOVA</a><i> </i>очень эффективен при анализе
планов с несбалансированной вложенностью (т.е.
когда вложенные факторы имеют различное число
уровней при разных уровнях факторов, в которые
они вложены), очень больших гнездовых планов
(например, с общим числом уровней более 200) или
иерархически вложенных планов (содержащих или не
содержащих <a href="../glossary/gloss_s.html#Random Effects">случайные
факторы</a>).</p>

<table ALIGN="RIGHT">
  <tr>
    <td><font SIZE="1"><a HREF="stanman.html#index">В начало</a></font></td>
  </tr>
</table>

<p><br>
</p>

<hr SIZE="1">

<p>&nbsp;</p>
<b>

<p><a name="analysis"></a></b><font size="5" color="navy">Ковариационный
анализ (ANCOVA)</font><b></p>

<p></b><font size="4" color="navy">Основная идея</font></p>

<p>В разделе <a href="stanman.html#basic">Основные идеи</a>
кратко обсуждалась идея управления факторами и
то, каким образом включение аддитивных факторов
позволяет уменьшить остаточную сумму квадратов
и увеличить статистическую мощность плана. Все
это может быть распространено и на переменные с
непрерывным множеством значений. Когда такие
непрерывные переменные включаются в план в
качестве факторов, они называются <i>ковариатами</i>.

<ul>
  <li><a href="stanman.html#afixed">Фиксированные ковариаты</a></li>
  <li><a href="stanman.html#achanging">Переменные ковариаты</a></li>
</ul>

<p>Для просмотра других разделов <i>Вводного
обзора </i>выберите соответствующее название
ниже. 

<ul>
  <li><a href="stanman.html#basic">Основные идеи</a></li>
  <li><a href="stanman.html#complex">Сложные планы</a></li>
  <li><a href="stanman.html#multivariate">Многомерные планы:
    многомерный дисперсионный и ковариационный
    анализ</a></li>
  <li><a href="stanman.html#contrast">Анализ контрастов и
    апостериорные критерии</a></li>
  <li><a href="stanman.html#assumptions">Предположения и последствия
    их нарушения</a></li>
</ul>

<p>См. также <a href="stanman.html#methods"><i>Методы
дисперсионного анализа</i></a>, <a href="stvarcom.html"><i>Компоненты
дисперсии и смешанные модели ANOVA/ANCOVA</i></a> и <a href="stexdes.html"><i>Планирование эксперимента</i></a>.</p>

<p><a NAME="afixed"></a><font size="4" color="navy">Фиксированные
ковариаты</font></p>

<p>Предположим, что сравниваются математические
навыки двух групп студентов, которые обучались
по двум различным учебникам. Предположим также,
что имеются дополнительные данные о
коэффициенте интеллекта (IQ) каждого студента.
Можно предположить, что коэффициент интеллекта
связан с математическими навыками, и
использовать эту информацию. Для каждой из двух
групп студентов можно вычислить коэффициент
корреляции между IQ и математическими навыками
(см. <a href="stbasic.html">Основные статистики и таблицы</a>).
Используя этот коэффициент корреляции, можно
выделить долю дисперсии в группах, объясняемую IQ
и необъясняемую долю дисперсии (см. также <a href="../esc.html">Элементарные понятия статистики</a> и <a href="stbasic.html">Основные статистики и таблицы</a>).
Оставшаяся доля дисперсии используется при
проведении анализа как дисперсия ошибки. Если
имеется корреляция между IQ и математическими
навыками, то таким образом можно существенно
уменьшить дисперсию ошибки <i>SS/(n-1)</i>.</p>
<b>

<p>Влияние ковариат на <i>F</i> критерий.</b> <a href="../glossary/gloss_f.html#F Distribution"><i>F</i> критерий</a>
оценивает статистическую значимость различия
средних в группах, при этом вычисляется
отношение межгрупповой дисперсии (<i>MS<font SIZE="1">ошибка</font></i>)
к дисперсии ошибок (<i>MS<font SIZE="1">ошибка</font></i>). Если
<i>MS<font SIZE="1">ошибка</font></i> уменьшается, например,
при учете фактора IQ, значение <i>F </i>увеличивается.</p>
<b>

<p>Множество ковариат. </b>Рассуждения,
использованные выше для одной ковариаты (IQ),
легко распространяются на несколько ковариат.
Например, кроме IQ, можно включить измерение
мотивации, пространственного мышления и т.д.
Вместо обычного коэффициента корреляции при
этом используется множественный коэффициент
корреляции (см. раздел <a href="stmulreg.html">Множественная
регрессия</a>).</p>
<b>

<p>Когда значение <i>F</i>-критерия уменьшается.</b>
Иногда введение ковариат в план эксперимента
уменьшает значение <i>F</i>-критерия<i>.</i> Обычно это
указывает на то, что ковариаты коррелированы не
только с зависимой переменной (например,
математическими навыками), но и с факторами
(например, с разными учебниками). Предположим, что
IQ измеряется в конце семестра, после почти
годового обучения двух групп студентов по двум
разным учебникам. Хотя студенты разбивались на
группы случайным образом, может оказаться, что
различие учебников настолько велико, что и IQ и
математические навыки в разных группах будут
сильно различаться. В этом случае, ковариаты не
только уменьшают дисперсию ошибок, но и
межгрупповую дисперсию. Другими словами, после
контроля за разностью IQ в разных группах,
разность в математических навыках уже будет
несущественной. Ту же мысль можно выразить иначе:
после &quot;исключения&quot; влияния IQ, неумышленно
исключается и влияние учебника на развитие
математических навыков. </p>
<b>

<p>Скорректированные средние. </b>Когда ковариата
влияет на межгрупповой фактор, следует вычислять
<i>скорректированные средние</i>, т.е. такие
средние, которые получаются после удаления всех
оценок ковариат.</p>
<b>

<p>Взаимодействие между ковариатами и факторами. </b>Также
как исследуется <a href="../glossary/gloss_v.html#Interactions">взаимодействие</a>
между факторами, можно исследовать
взаимодействия между ковариатами и группами
факторов. Предположим, что один из учебников
особенно подходит для умных студентов. Второй
учебник для умных студентов скушен, а для менее
умных студентов этот же учебник труден. В
результате имеется положительная корреляция
между IQ и результатом обучения в первой группе
(более умные студенты, лучше результат) и нулевая
или небольшая отрицательная корреляция во
второй группе (чем умнее студент, тем менее
вероятно приобретение математических навыков из
второго учебника). В некоторых исследованиях эта
ситуация обсуждается как пример нарушения
предположений ковариационного анализа (см. <a href="stanman.html#assumptions">Предположения и последствия их
нарушения</a>). Однако так как в модуле
Дисперсионный анализ используются самые общие
способы ковариационного анализа, можно, в
частности, оценить статистическую значимость <a href="../glossary/gloss_v.html#Interactions">взаимодействия</a> между
факторами и ковариатами.</p>

<p><a NAME="achanging"></a><font size="4" color="navy">Переменные
ковариаты</font></p>

<p>В то время как фиксированные ковариаты
обсуждаются в учебниках достаточно часто,
переменные ковариаты упоминаются намного реже.
Обычно, при проведении экспериментов с
повторными измерениями, нас интересуют различия
в измерениях одних и тех же величин в разные
моменты времени. А именно, нас интересует
значимость этих различий. Если одновременно с
измерениями зависимых переменных проводится
измерение ковариат, можно вычислить корреляцию
между ковариатой и зависимой переменной.
Например, можно изучать интерес к математике и
математические навыки в начале и в конце
семестра. Интересно было бы проверить,
коррелированы ли между собой изменения в
интересе к математике с изменением
математических навыков. Модуль <i>Дисперсионный
анализ </i>в <i>STATISTICA</i> автоматически оценивает
статистическую значимость изменения ковариат в
тех планах, где это возможно. </p>

<table ALIGN="RIGHT">
  <tr>
    <td><font SIZE="1"><a HREF="stanman.html#index">В начало</a></font> </td>
  </tr>
</table>

<p><br>
<br CLEAR="RIGHT">
</p>

<hr SIZE="1">

<p><a NAME="multivariate"></a></p>

<p><font size="5" color="navy">Многомерные планы: Многомерный
дисперсионный и ковариационный анализ</font> 

<ul>
  <li><a href="stanman.html#mbetween">Межгрупповые планы</a></li>
  <li><a href="stanman.html#mrepeated">Планы с повторными
    измерениями</a></li>
  <li><a href="stanman.html#msum">Суммы значений переменной и
    многомерный дисперсионный анализ</a></li>
</ul>

<p>Для просмотра других обзорных разделов
выберите соответствующее название ниже. 

<ul>
  <li><a href="stanman.html#basic">Основные идеи</a></li>
  <li><a href="stanman.html#complex">Сложные планы</a></li>
  <li><a href="stanman.html#analysis">Ковариационный анализ (ANCOVA)</a></li>
  <li><a href="stanman.html#contrast">Анализ контрастов и
    апостериорные критерии</a></li>
  <li><a href="stanman.html#assumptions">Предположения и последствия
    их нарушения</a></li>
</ul>

<p>См. также <a href="stanman.html#methods">Методы
дисперсионного анализа</a>, <u><a href="stvarcom.html">Компоненты
дисперсии и смешанные модели ANOVA/ANCOVA</a></u> и <a href="stexdes.html">Планирование эксперимента</a>.</p>

<p><a NAME="mbetween"></a><font size="4" color="navy">Межгрупповые планы</font></p>

<p>Все рассматриваемые ранее примеры включали
только одну зависимую переменную. Когда
одновременно имеется несколько зависимых
переменных, возрастает лишь сложность
вычислений, а содержание и основные принципы не
меняются. Например, проводится исследование двух
различных учебников. При этом изучаются успехи
студентов в изучении физики и математики. В этом
случае имеются две зависимые переменные и нужно
выяснить, как влияют на них одновременно два
разных учебника. Для этого можно воспользоваться
многомерным дисперсионным анализом (MANOVA). Вместо
одномерного <i>F </i>критерия, используется
многомерный <i>F</i> критерий (<i>лямбда-критерий
Уилкса</i>), основанный на сравнении
ковариационной матрицы ошибок и межгрупповой
ковариационной матрицы. Если зависимые
переменные коррелированы между собой, то эта
корреляция должна учитываться при вычислении
критерия значимости. Очевидно, если одно и то же
измерение повторяется дважды, то ничего нового
получить при этом нельзя. Если к имеющемуся
измерению добавляется коррелированное с ним
измерение, то получается некоторая новая
информация, но при этом новая переменная
содержит избыточную информацию, которая
отражается в ковариации между переменными. </p>

<p>Интерпретация результатов. Если общий
многомерный критерий значим, можно заключить,
что соответствующий эффект (например, тип
учебника) значим. Однако встают следующие
вопросы. Влияет ли тип учебника на улучшение
только математических навыков, только
физических навыков, или одновременно на
улучшение тех и других навыков. В
действительности, после получения значимого
многомерного критерия, для отдельного главного
эффекта или взаимодействия исследуются
одномерные <a HREF="../glossary/gloss_f.html#F Distribution">F-критерии</a>.
Другими словами, отдельно исследуются зависимые
переменные, которые вносят вклад в значимость
многомерного критерия.</p>

<p><a NAME="mrepeated"></a><font size="4" color="navy">Планы с повторными
измерениями</font></p>

<p>Если измеряются математические и физические
навыки студентов в начале семестра и в конце
семестра, то это и есть повторные измерения.
Изучение критерия значимости в таких планах это
логическое развитие одномерного случая. Заметим,
что методы многомерного дисперсионного анализа
обычно также используются для исследования
значимости <i>одномерных</i> факторов повторных
измерений, имеющих более чем два уровня.
Соответствующие применения будут рассмотрены
позднее в этой части.</p>

<p><a name="msum"></a><font size="4" color="navy">Суммы значений
переменной и дисперсионный анализ</font></p>

<p>Даже опытные пользователи одномерного и
многомерного дисперсионного анализа часто
приходят в затруднение, получая разные
результаты при применении многомерного
дисперсионного анализа, например, для трех
переменных, и при применении одномерного
дисперсионного анализа к сумме этих трех
переменных, как к одной переменной. Идея <i>суммирования</i>
переменных состоит в том, что каждая переменная
содержит в себе некоторую истинную переменную,
которая и исследуется, а также случайную ошибку
измерения. Поэтому при усреднении значений
переменных, ошибка измерения будет ближе к 0 для
всех измерений и усредненное значений будет
более надежным. На самом деле, в этом случае
применение дисперсионного анализа к сумме
переменных разумно и является мощным методом.
Однако, если зависимые переменные по своей
природе многомерны, то суммирование неуместно.
Например, пусть зависимые переменные состоят из
четырех показателей <i>успеха в обществе</i>.
Каждый показатель характеризует совершенно
независимую сторону человеческой деятельности
(например, профессиональный успех, преуспевание
в бизнесе, семейное благополучие и т.д.). Сложение
этих переменных подобно сложению яблока и
апельсина. Сумма этих переменных не будет
подходящим одномерным показателем. Поэтому с
такими данными нужно обходится как с
многомерными показателями в <i>многомерном
дисперсионном анализе</i>. </p>

<table ALIGN="RIGHT">
  <tr>
    <td><font SIZE="1"><a HREF="stanman.html#index">В начало</a></font></td>
  </tr>
</table>

<p><br>
</p>

<hr SIZE="1">

<p>&nbsp;</p>

<p><a name="contrast"></a><font size="5" color="#000080">Анализ контрастов
и апостериорные критерии</font> 

<ul>
  <li><a HREF="stanman.html#pwhy">Почему сравниваютсяотдельные
    множества средних?</a> </li>
  <li><a HREF="stanman.html#pcontrast">Анализ контрастов</a> </li>
  <li><a HREF="stanman.html#ppost">Апостериорные критерии</a></li>
</ul>

<p>Для просмотра других обзорных разделов
выберите соответствующее название ниже. 

<ul>
  <li><a href="stanman.html#basic">Основные идеи</a></li>
  <li><a href="stanman.html#complex">Сложные планы</a></li>
  <li><a href="stanman.html#analysis">Ковариационный анализ (ANCOVA)</a></li>
  <li><a HREF="stanman.html#multivariate">Многомерные планы:
    многомерный дисперсионный и ковариационный
    анализ</a> </li>
  <li><a href="stanman.html#assumptions">Предположения и последствия
    их нарушения</a></li>
</ul>

<p>См. также <a href="stanman.html#methods">Методы
дисперсионного анализа</a>, <u><a href="stvarcom.html">Компоненты
дисперсии и смешанные модели ANOVA/ANCOVA</a></u> и <a href="stexdes.html">Планирование эксперимента</a>.</p>

<p><a name="pwhy"></a><font size="4" color="#000080">Почему сравниваются
отдельные множества средних?</font></p>

<p>Обычно гипотезы относительно
экспериментальных данных формулируются не
просто в терминах главных эффектов или <a href="../glossary/gloss_v.html#Interactions">взаимодействий</a>.
Примером может служить такая гипотеза: некоторый
учебник повышает математические навыки только у
студентов мужского пола, в то время как другой
учебник примерно одинаково эффективен для обоих
полов, но все же менее эффективен для мужчин.
Можно предсказать, что эффективность учебника
взаимодействует с полом студента. Однако этот
прогноз касается также <i>природы</i>
взаимодействия. Ожидается значительное различие
между полами, обучающимися по одной книге, и
практически не зависимые от пола результаты для
обучающихся по другой книге. Такой тип гипотез
обычно исследуется с помощью анализа контрастов.</p>

<p><a name="pcontrast"></a><font size="4" color="#000080">Анализ
контрастов</font></p>

<p>Если говорить коротко, то анализ контрастов
позволяет оценивать статистическую значимость
некоторых линейных комбинаций факторов сложного
плана. Анализ контрастов главный и обязательный
элемент любого сложного плана дисперсионного
анализа. Модуль <i>Дисперсионный анализ</i> имеет
достаточно разнообразные возможности анализа
контрастов, которые позволяют выделять и
анализировать любые типы сравнений средних
(способы задания контрастов описаны в разделе
Примечания).</p>
<font color="navy" size="3">

<p></font><a name="ppost"></a><font size="4" color="#000080">Апостериорные
критерии</font></p>

<p>Иногда в результате обработки эксперимента
обнаруживаются неожиданные различия в средних.
Хотя в большинстве случаев творческий
исследователь сможет объяснить эти различия, ему
сложно провести дальнейший анализ. Эта проблема
является одной из тех, для которых используются <i>апостериорные
критерии</i>, то есть критерии, не использующие <i>априорные</i>
гипотезы. Для иллюстрации рассмотрим следующий
эксперимент. Предположим, что на 100 карточках
записаны числа от 1 до 10. Опустив все эти карточки
в шапку, мы случайным образом выбираем 20 раз по 5
карточек, и вычисляем для каждой выборки среднее
значение (среднее чисел, записанных на карточки).
Можно ли ожидать, что найдется две выборки, у
которых средние значения значимо отличаются? Это
очень правдоподобно! Выбирая две выборки с
максимальным и минимальным средним, можно
получить разность средних значений, сильно
отличающуюся от разности средних значений,
например, первых двух выборок. Эту разность можно
исследовать, например, с помощью анализа
контрастов. Если не вдаваться в детали, то
существует несколько, так называемых <i>апостериорных</i>
критериев, которые основаны в точности на первом
сценарии (взятие экстремальных средних из 20
выборок), т. е. эти критерии основаны на выборе
наиболее отличающихся средних для сравнения
всех<i> </i>средних значений в плане. Модуль <i>Дисперсионный
анализ</i> предлагает широкий выбор таких
критериев. Когда в эксперименте встречаются
неожиданные результаты, то используются <i>апостериорные</i>
процедуры для исследования их статистической
значимости.</p>

<table ALIGN="RIGHT">
  <tr>
    <td><font SIZE="1"><a HREF="stanman.html#index">В начало</a></font></td>
  </tr>
</table>

<p><br>
</p>

<hr SIZE="1">

<p>&nbsp;</p>

<p><a name="assumptions"></a><font size="5" color="#000080">Предположения и
последствия их нарушения</font> </p>

<p>&nbsp; 

<ul>
  <li><a href="stanman.html#deviation">Отклонение от предположения о
    нормальности распределений</a></li>
  <li><a href="stanman.html#homogeneity">Однородность дисперсии</a></li>
  <li><a href="stanman.html#2">Однородность дисперсии и
    ковариаций</a></li>
  <li><a href="stanman.html#sphericity">Сферичность и сложная
    симметрия</a> </li>
</ul>

<p>&nbsp; Для просмотра других обзорных разделов
выберите соответствующее название ниже. 

<ul>
  <li><a href="stanman.html#basic">Основные идеи</a></li>
  <li><a href="stanman.html#complex">Сложные планы</a></li>
  <li><a href="stanman.html#analysis">Ковариационный анализ (ANCOVA)</a></li>
  <li><a href="stanman.html#multivariate">Многомерные планы:
    многомерный дисперсионный и ковариационный
    анализ</a></li>
  <li><a href="stanman.html#contrast">Анализ контрастов и
    апостериорные критерии</a></li>
</ul>

<p>См. также <a href="stanman.html#methods">Методы
дисперсионного анализа</a>, <a href="stvarcom.html">Компоненты
дисперсии и смешанные модели ANOVA/ANCOVA</a> и <a href="stexdes.html">Планирование эксперимента</a>.</p>

<p><a name="deviation"></a><font size="4" color="#000080">Нормальность
распределения</font></p>

<p><strong>Предположения.</strong> Имеются следующие
предположения дисперсионного анализа: зависимая
переменная измерена в <a href="../glossary/gloss_i.html%20#Interval Scale">интервальной шкале</a>
(см. раздел <a href="../esc.html"><i>Элементарные понятия
статистики</i></a>); зависимая переменная имеет
нормальное распределение внутри каждой группы.
Модуль <i>Дисперсионный анализ</i> содержит
широкий набор графиков и статистик для проверки
этих предположений.</p>

<p><strong>Эффекты нарушения.</strong> Вообще <a href="../glossary/gloss_f.html#F Distribution"><i>F</i>-критерий</a> очень
устойчив к отклонению от нормальности (подробнее
см. Lindman, 1974). Если <a href="../glossary/gloss_ae.html%20#Kurtosis">эксцесс</a>
(см. <a href="stbasic.html"><i>Основные статистики и таблицы</i></a>)
больше 0, то значение статистики <i>F</i> может стать
очень маленьким. Нулевая гипотеза при этом не
может быть отвергнута, хотя она и не верна.
Ситуация меняется на противоположную, если
эксцесс меньше 0. <a href="../glossary/gloss_a.html#Skewness">Асимметрия</a>
распределения обычно незначительно влияет на <i>F</i>
статистику. Если число наблюдений в ячейке
достаточно большое, то отклонение от
нормальности не имеет особого значения в силу <i>центральной
предельной теоремы</i>, в соответствии с которой,
распределение среднего значения при большом
объеме выборки близко к нормальному, независимо
от начального распределения. Подробное
обсуждение устойчивости <i>F</i> статистики можно
найти в Box and Anderson (1955) или Lindman (1974).</p>

<p><a name="homogeneity"></a><font size="4" color="#000080">Однородность
дисперсии</font></p>

<p><b>Предположения. </b>Предполагается, что
дисперсии в разных группах одинаковы. Это
предположение называется предположением об <i>однородности
дисперсии. </i>Напомним, что в предыдущих разделах
описывая вычисление суммы квадратов ошибок мы
производили суммирование внутри каждой группы.
Если дисперсии в двух группах отличаются друг от
друга, то сложение их не естественно и не дает
верной оценки общей внутригрупповой дисперсии
(так как в этом случае общей дисперсии вообще не
существует). Модуль <i>Дисперсионный анализ
-ANOVA/MANOVA</i> содержит большой набор статистических
критериев, позволяющих обнаружить
неоднородность дисперсии.</p>
<b>

<p>Эффекты нарушения. </b>Линдман (Lindman 1974, стр. 33)
показывает, что <i>F</i> критерий вполне устойчив
относительно нарушения предположений
однородности дисперсии (см. также Box, 1954a, 1954b; Hsu,
1938). </p>
<b>

<p><a NAME="assumptions3"></a>Специальный случай:
коррелированность средних и дисперсий. </b>Бывают
случаи, когда <i>F </i>статистика может <i>вводить в
заблуждение. </i>Это бывает, когда в ячейках плана
средние значения коррелированы с дисперсией.
Модуль <i>Дисперсионный анализ </i>позволяет
строить <a href="../glossary/gloss_2m.html#Scatterplot, 2D">диаграммы
рассеяния</a> дисперсии или стандартного
отклонения относительно средних для обнаружения
такой корреляции. Причина, по которой такая
корреляция опасна, состоит в следующем.
Представим себе, что имеется 8 ячеек в плане, 7 из
которых имеют почти одинаковое среднее, а в одной
ячейке среднее намного больше остальных. Тогда <i>F</i>
критерий может обнаружить статистически
значимый эффект. Но предположим, что в ячейке с
большим средним значением и дисперсия
значительно больше остальных, т.е. среднее
значение и дисперсия в ячейках зависимы (чем
больше среднее, тем больше дисперсия). В этом
случае большое среднее значение ненадежно, так
как оно может быть вызвано большой дисперсией
данных. Однако <i>F </i>статистика, основанная на <i>объединенной
</i>дисперсии внутри ячеек, будет фиксировать
большое среднее, хотя критерии, основанные на
дисперсии в каждой ячейке не все различия в
средних будут считать значимыми. </p>

<p>Такой характер данных (большое среднее и
большая дисперсия) часто встречается, когда
имеются резко выделяющиеся наблюдения. Одно или
два резко выделяющихся наблюдений сильно
смещают среднее значение и очень увеличивают
дисперсию. </p>

<p><a name="2"></a><font size="4" color="#000080">Однородность
дисперсии и ковариаций</font></p>

<p><b>Предположения.</b> В многомерных планах, с
многомерными зависимыми измерениями, также
применяются предположение об однородности
дисперсии, описанные ранее. Однако так как
существуют многомерные зависимые переменные, то
требуется так же чтобы их взаимные корреляции
(ковариации) были однородны по всем ячейкам
плана. Модуль <i>Дисперсионный анализ</i>
предлагает разные способы проверки этих
предположений. </p>

<p><b>Эффекты нарушения.</b> Многомерным аналогом <i>F-</i>
критерия является лямбда-критерий Уилкса. Не так
много известно об устойчивости (робастности)
лямбда-критерия Уилкса относительно нарушения
указанных выше предположений. Тем не менее, так
как интерпретация результатов модуля <i>Дисперсионный
анализ</i> основывается обычно на значимости
одномерных эффектов (после установления
значимости общего критерия), обсуждение
робастности касается, в основном, одномерного
дисперсионного анализа. Поэтому должна быть
внимательно исследована значимость одномерных
эффектов. </p>

<p><b>Специальный случай:ковариационный анализ.</b>
Особенно серьезные нарушения однородности
дисперсии/ковариаций могут происходить, когда в
план включаются ковариаты. В частности, если
корреляция между ковариатами и зависимыми
измерениями различна в разных ячейках плана,
может последовать неверное истолкование
результатов. Следует помнить, что в
ковариационном анализе, в сущности, проводится
регрессионный анализ внутри каждой ячейки для
того, чтобы выделить ту часть дисперсии, которая
соответствует ковариате. Предположение об
однородности дисперсии/ковариации предполагает,
что этот регрессионный анализ проводится при
следующем ограничении: все регрессионные
уравнения (наклоны) для всех ячеек одинаковы.
Если это не выполняется, могут появиться большие
ошибки. Модуль <i>Дисперсионный анализ </i>имеет
несколько специальных критериев для проверки
этого предположения. Можно посоветовать
использовать эти критерии, для того, чтобы
убедиться, что регрессионные уравнения для
различных ячеек примерно одинаковы.</p>

<p><a name="sphericity"></a><font size="4" color="#000080">Сферичность и
сложная симметрия</font></p>

<p><font size="3"><strong>Причины использования
многомерного подхода к повторным измерениям в
дисперсионном анализе. </strong>В планах, содержащих
факторы повторных измерений с более чем двумя
уровнями, применение одномерного дисперсионного
анализа требует дополнительных предположений:
предположения о <i>сложной симметрии </i>и о <i>сферичности</i>.
Эти предположения редко выполняются (см. ниже).
Поэтому в последние годы многомерный
дисперсионный анализ завоевал популярность в
таких планах (оба подхода совмещены в модуле <i>Дисперсионный
анализ</i>). Предположение о сложной симметрии
состоит в том, что дисперсии (общие
внутригрупповые) и ковариации (внутри групп) для
различных повторных измерений однородны
(одинаковы). Это достаточное условие для того,
чтобы одномерный <i>F</i> критерий для повторных
измерений был обоснованным (т.е. выданные
F-значения в среднем соответствовали <a href="../glossary/gloss_f.html#F Distribution"><em>F</em>-распределению</a>).
Однако, в данном случае, это не условие не
является необходимым. Условие сферичности
является необходимым и достаточным условием для
обоснованного применения F-критерия. Смысл
условия состоит в том, что внутри групп все
наблюдения должны быть независимы и одинаково
распределены. Природа этих предположений, а
также влияние их нарушений обычно не очень
хорошо описаны в книгах по дисперсионному
анализу. Мы даем это описание в следующих
параграфах. Там же будет показано, что результаты
одномерного подхода могут отличаться от
результатов многомерного подхода, и будет
объяснено, что это означает. </p>
<b>

<p>Необходимость независимости гипотез.</b> Общий
способ анализа данных в дисперсионном анализе -
это <i>подгонка модели</i>. Если относительно
модели, соответствующей данным, имеются
некоторые <i>априорные </i>гипотезы, то дисперсия
разбивается для проверки этих гипотез (проверка
главных эффектов, <a href="../glossary/gloss_v.html#Interactions">взаимодействий</a>).
С вычислительной точки зрения этот подход строит
некоторое множество контрастов (множество
сравнений средних в плане). Однако если контрасты
не независимы друг от друга, то разбиение
дисперсии на компоненты не имеет смысла.
Например, если два контраста <i>A</i> и <i>B</i>
тождественны, то соответственная им компонента
дисперсии выделяется дважды. Например, глупо и
бессмысленно выделять две гипотезы: &quot;среднее в
ячейке 1 выше среднего в ячейке 2&quot; и &quot;среднее
в ячейке 1 выше среднего в ячейке 2&quot;. Итак,
гипотезы должны быть независимы или
ортогональны (термин <i>ортогональность</i>
впервые использован в работе Yates, 1933).</p>
<b>

<p>Независимые гипотезы при повторных измерениях.
</b>Общий <a href="../glossary/gloss_a.html#Algorithm">алгоритм</a>,
реализованный в модуле<i> Дисперсионный анализ</i>,
будет пытаться для каждого эффекта генерировать
независимые (ортогональные) контрасты (см. раздел
<i>Технические замечания</i> руководства
пользователя). Для фактора повторных измерений
эти контрасты задают множество гипотез
относительно <i>разностей </i>между уровнями
рассматриваемого фактора. Однако если эти
разности коррелированы внутри групп, то
результирующие контрасты не являются больше
независимыми. Например, в обучении, где
обучающиеся измеряются три раза за один семестр,
может случиться, что изменения между 1 и 2
измерением отрицательно коррелируют с
изменением между 2 и 3 измерениями субъектов. Те,
кто большую часть материала освоил между 1 и 2
измерениями, осваивают меньшую часть в течение
того времени, которое прошло между 2 и 3
измерением. В действительности, для большинства
случаев, где дисперсионный анализ используются
при повторных измерениях, можно предположить,
что изменения по уровням коррелированы по
субъектам. Однако когда это происходит,
предположение о сложной симметрии и сферичности
не выполняются и независимые контрасты не могут
быть вычислены. </p>
<b>

<p>Влияние нарушений и способы их исправления. </b>Когда
предположения о сложной симметрии или о
сферичности не выполняются, дисперсионный
анализ может выдать ошибочные результаты. До
того, как были достаточно разработаны
многомерные процедуры, было предложено
несколько предположений для компенсации
нарушений этих предположений. (См., например,
работы Greenhouse &amp; Geisser, 1959 и Huynh &amp; Feldt, 1970). Эти
методы до сих пор широко используются (поэтому
они представлены в модуле <i>Дисперсионный анализ</i>).
</p>
<b>

<p>Подход многомерного дисперсионного анализа к
повторным измерениям.</b> В целом проблемы сложной
симметрии и сферичности относятся к тому факту,
что множества контрастов, включенных в
исследование эффектов факторов повторных
измерений (с числом уровней больше двух) не
независимы друг от друга. Однако им не
обязательно быть независимыми, если
используется <i>многомерный </i>критерий для
одновременной проверки статистического
значимости двух или более контрастов фактора
повторных измерений. Это является причиной того,
что методы многомерного дисперсионного анализа
стали чаще использоваться для проверки
значимости факторов одномерных повторных
измерений с более чем 2 уровнями. Этот подход
широко распространен, так как он, в общем случае,
не требует предположения о сложной симметрии и
предположения о сферичности.</p>
<b>

<p>Случаи, в которых подход<i> </i>многомерного
дисперсионного анализа не может быть
использован. </b>Существуют примеры (планы), когда
подход многомерного дисперсионного анализа не
может быть применен. Обычно это случаи, когда
имеется небольшое количество субъектов в плане и
много уровней в факторе повторных измерений.
Тогда для проведения многомерного анализа может
быть слишком мало наблюдений. Например, если
имеется 12 субъектов, <i>p = 4</i> фактора повторных
измерений, и каждый фактор имеет <i>k = 3</i> уровней.
Тогда взаимодействие 4-х факторов будет
&quot;расходовать&quot;<i> (k-1)p = 24 = 16</i> степеней
свободы. Однако имеется лишь 12 субъектов,
следовательно, в этом примере многомерный тест
не может быть проведен. Модуль <i>Дисперсионный
анализ</i> самостоятельно обнаружит эти
наблюдения и вычислит только одномерные
критерии.</p>
<b>

<p>Различия в одномерных и многомерных
результатах.</b> Если исследование включает
большое количество повторных измерений, могут
возникнуть случаи, когда одномерный подход
дисперсионного анализа к повторным измерениям
дает результаты, сильно отличающиеся от тех,
которые были получены при многомерном подходе.
Это означает, что разности между уровнями
соответствующих повторных измерений
коррелированы по субъектам. Иногда этот факт
представляет некоторый самостоятельный интерес.</p>

<p>&nbsp;</p>

<hr SIZE="1">

<p>&nbsp;</p>

<p></font><a name="methods"></a><font size="5" color="#000080">Методы
дисперсионного анализа</font></p>

<p>Методы дисперсионного анализа обсуждаются в
нескольких разделах этого учебника. Хотя многие
из доступных статистических методов описываются
одновременно в нескольких главах, каждый из них
наиболее удобен при работе в определенной
области приложений. </p>

<p><b><a HREF="stanman.html">Диспресионный анализ</a>:</b> Эта
глава включает обзор полнофакторных планов, <a HREF="stanman.html#mrepeated">планов с повторными измерениями</a>,
<a HREF="stanman.html#multivariate">планов многомерного
дисперсионного и ковариационного анализа (MANOVA)</a>,
планов с балансированной <a HREF="../glossary/gloss_v.html#Nested Factors">вложенностью</a> (планы
бывают не сбалансированными, т.е. имеющими
различные размеры выборок <i>n</i> при некоторых
испытаниях), а также описание оценивания <a HREF="stanman.html#contrast">спланированных и апостериорных
сравнений</a> и мн. др. </p>

<p><b><a HREF="stvarcom.html">Компоненты дисперсии и
смешанная модель ANCOVA</a>:</b> Эта глава включает
обсуждение экспериментов со <a HREF="../glossary/gloss_s.html#Random Effects">случайными эффектами</a>
(смешанная модель дисперсионного анализ),
оценивание <a HREF="../glossary/gloss_k.html#Variance Components">компонент
дисперсии</a> для случайных эффектов, планов с
большими главными эффектами (например, с
факторами, имеющими более 100 уровней) с/без
случайных эффектов, а также в случае планов с
большим числом факторов, когда необходимо
оценить все <a HREF="../glossary/gloss_v.html#Interactions">взаимодействия</a>.
</p>

<p><b><a HREF="stexdes.html">Планирование эксперимента</a>:</b>
Эта глава включает обсуждение стандартных
экспериментальных планов, используемых в
промышленных/производственных приложениях,
включая <a HREF="stexdes.html#2">2**(k-p)</a> и <a HREF="stexdes.html#3">3**(k-p)</a>
планы, <a HREF="stexdes.html#central">центральные
композиционные и нефакторные планы</a>, <a HREF="stexdes.html#mixture">планы для смесей</a>, <a HREF="stexdes.html#construction">D- и A-оптимальные планы</a>, а
также планы для произвольных <a HREF="stexdes.html#designs">ограниченных
областей значений экспериментальных данных</a>. </p>

<p><b><a HREF="stprocan.html#gage">Анализ повторяемости и
воспроизводимости</a> (в главе <em>Анализ процессов</em>):</b>
Этот раздел главы <a HREF="stprocan.html"><i>Анализ
процессов</i></a> включает обсуждение планов
специального вида, используемых для оценивания
надежности и точности измерительных устройств;
Эти планы обычно включают два или три <a HREF="../glossary/gloss_s.html#Random Effects">случайных фактора</a> и
набор специализированных статистик, позволяющих
оценить качество измерительной системы (обычно в
промышленных/производственных приложениях). </p>

<p><b><a HREF="stbasic.html#Breakdown: Descriptive statistics by groups">Таблицы
группировки</a> (в главе Основные статистики и
таблицы):</b> Эта глава включает обсуждение
экспериментов, одного (многоуровневого) или
нескольких (любых) факторов в случаях, когда не
требуется проведение полного дисперсионного
анализа. </p>

<p>Дополнительная информация по методам анализа данных, добычи данных, 
визуализации и прогнозированию содержится на 
<a href="http://www.statsoft.ru/home/portal/default.asp" target="_blank">Портале StatSoft</a> (http://www.statsoft.ru/home/portal/default.asp) 
и в <a href="http://www.statsoft.ru/home/portal/textbook2/default.htm" target="_blank">Углубленном Учебнике StatSoft (Учебник с формулами)</a>.</p>

<table ALIGN="RIGHT">
  <tr>
    <td><a HREF="stanman.html#index"><font SIZE="1">В начало</font></a> </td>
  </tr>
</table>

<p><br>
<br>
<br>
</p>

<hr SIZE="1">

<p align="center"><br>
<img SRC="../stathoms.jpg" ALIGN="LEFT" WIDTH="151" HEIGHT="41"> <br CLEAR="ALL">
<font SIZE="1">(c) Copyright StatSoft, Inc., 1984-2001<br>
STATISTICA является торговой маркой StatSoft, Inc. </font></p>

<hr SIZE="1">
</body>
</html>
