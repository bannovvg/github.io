<html>

<head>
<title>Электронный учебник - Словарь В</title>
</head>

<body BACKGROUND="../tile1.gif">

<p><a NAME="PNN"><font SIZE="4" COLOR="navy">Вероятностные нейронные
сети (PNN).</font></a> Вид <a HREF="gloss_n.html#Neural Networks">нейронных
сетей</a>&nbsp; для задач <a HREF="gloss_k.html#Classification">классификации</a>,
где плотность вероятности принадлежности
классам оценивается посредством ядерной
аппроксимации. Один из видов так называемых
байесовых сетей (Speckt, 1990; Patterson, 1996; Bishop, 1995). См.
раздел&nbsp; <a HREF="../modules/stneunet.html">Нейронные сети</a>.<br>
</p>

<p><a NAME="Interactions"><font SIZE="4" COLOR="navy">Взаимодействия.</font></a>
Эффект <em>взаимодействия</em> возникает, когда
зависимость между двумя или более переменными
изменяется под воздействием одной или
нескольких других переменных. Другими словами,
сила или знак (направление взаимодействия)
зависимости между двумя или более переменными
зависит от значения принимаемого некоторыми
другими переменными. Термин <em>взаимодействие</em>
был впервые использован в работе Фишера (Fisher, 1926).
Отметим, что слово &quot;зависит&quot; в данном
контексте не означает причинной зависимости, а
просто отражает тот факт, что в зависимости от
рассматриваемого подмножества наблюдений (от
значения модифицирующей переменной или
переменных) характер зависимости будет меняться
(модифицироваться).</p>

<p>Предположим, что имеется две группы студентов,
причем психологически студенты первой группы
настроены на выполнение поставленных задач и
более целеустремленны, чем студенты второй
группы, состоящей из более ленивых студентов.
Разобьем каждую группу случайным образом
пополам и предложим одной половине в каждой
группе сложное задание, а другой - легкое. После
этого измерим, насколько напряженно студенты
работают над этими заданиями. Средние значения
для этого (вымышленного) исследования показаны в
таблице:</p>

<table BORDER="1">
  <tr>
    <td>&nbsp;</td>
    <th align="center"><font size="2" color="BLUE">Целеустремленные</font></th>
    <th align="center"><font size="2" color="BLUE">Ленивые</font></th>
  </tr>
  <tr>
    <th align="right"><font size="2" color="BLUE">Трудное задание<br>
    Легкое задание</font></th>
    <td align="center"><font size="2" color="BLUE">10<br>
    &nbsp;&nbsp;5</font></td>
    <td align="center"><font size="2" color="BLUE">&nbsp;&nbsp;5<br>
    10</font></td>
  </tr>
</table>

<p>Какой вывод можно сделать из этих результатов?
Можно ли заключить, что: (1) над сложным заданием
студенты трудятся более напряженно; (2)
честолюбивые студенты работают упорнее, чем
ленивые? Ни одно из этих утверждений не отражает
сущность систематического характера средних,
приведенных в таблице. Анализируя результаты,
правильнее было бы сказать, что над сложными
заданиями работают упорнее только честолюбивые
студенты, в то время как над легкими заданиями
только ленивые работают упорнее. Другими
словами, характер студентов и сложность задания, <em>взаимодействуя</em>
между собой, влияют на затрачиваемое усилие. Это
пример <em>парного взаимодействия</em> между
характером студентов и сложностью задания.
(Отметим, что утверждения 1 и 2 описывают <em>главные
эффекты</em>.)</p>

<p>Для получения дополнительной информации о <em>взаимодействиях</em>
см. раздел <a HREF="../modules/stanman.html#binteraction"><i>Эффекты
взаимодействия</i></a>&nbsp; в главе <a HREF="../modules/stanman.html">Дисперсионный
анализ</a>.<br>
</p>

<p><a NAME="Weigend Regularization"><font SIZE="4" COLOR="navy">Вигенда
регуляризация.</font></a> Модифицированный вариант
функции ошибок для алгоритмов итерационного
обучения, в котором большим весам приписывается
штраф, так что <a HREF="gloss_n.html#Neural Networks">сеть</a> сама
находит для себя нужный уровень сложности и
избегает <a HREF="gloss_p.html#Overlearning">переобучения</a> (Weigend
et. al., 1991). См. раздел&nbsp; <a HREF="../modules/stneunet.html">Нейронные
сети</a>.<br>
</p>

<p><a NAME="Nested Factors"><font SIZE="4" COLOR="navy">Вложенные факторы.</font></a>
Во вложенных планах уровни факторов вложены
(этот термин был впервые использован в работе
Ganguli, 1941) внутри уровней другого фактора.
Например, если необходимо провести четыре
различных теста в четырех разных классах (т.е.
имеется межгрупповой фактор с четырьмя
уровнями), причем два из этих классов находятся в
школе A, а два других класса находятся в школе B, то
уровни первого фактора (4 различных теста)
вложены во второй фактор (2 разных школы).</p>

<p>См. также раздел <a HREF="../modules/stanman.html">Дисперсионный
анализ</a>.<br>
</p>

<p><a NAME="Outer Arrays"><font SIZE="4" COLOR="navy">Внешние массивы.</font></a>
При проведении анализа Тагучи, повторные
измерения откликов часто производятся
систематическим образом, чтобы контролировать
факторы шума. Уровни этих факторов в этом случае
располагаются в так называемых внешних массивах,
т.е. в ортогональных планах эксперимента. Однако
обычно повторные измерения размещаются в
отдельных столбцах электронной таблицы (т.е. в
другой переменной); поэтому индекс i (в формулах
&quot;чем-меньше-тем-лучше&quot;,
&quot;чем-больше-тем-лучше&quot; и др.) пробегает
номера столбцов всех переменных электронной
таблицы, либо уровни всех факторов во внешнем
массиве.</p>

<p>См. раздел <a HREF="../modules/stexdes.html#taguchic">Отношение
сигнал/шум</a>.<br>
</p>

<p><a NAME="Intraclass Correlation"><font SIZE="4" COLOR="navy">Внутриклассовый
коэффициент корреляции.</font></a> Значение
внутриклассового коэффициента корреляции для
популяции является мерой однородности
наблюдений внутри классов случайного фактора
относительно изменчивости наблюдений между
классами. Он равен нулю только в случае, когда
оцениваемый эффект <a HREF="gloss_s.html#Random Effects">случайного
фактора</a>&nbsp; равен нулю, и достигает единицы
только если оцениваемый эффект ошибки равен
нулю, при условии, что общая дисперсия наблюдений
отлична от нуля (см. работу Hays, 1988, стр. 485). </p>

<p>Отметим, что <em>внутриклассовый коэффициент
корреляции</em> может быть измерен с помощью
метода оценивания компонент дисперсии (см.
раздел <a HREF="../modules/stvarcom.html#estim3">Компоненты
дисперсии и смешанная модель ANOVA/ANCOVA </a>).<br>
</p>

<p><a NAME="Time Series"><font SIZE="4" COLOR="navy">Временные ряды.</font></a>
<em>Временной ряд</em> - это последовательность
измерений в последовательные моменты времени. <a HREF="../modules/sttimser.html">Анализ <em>временных рядов</em></a>
&nbsp; включает широкий спектр <a HREF="../modules/stdatmin.html#eda">разведочных</a>
процедур и исследовательских методов, которые
ставят две основные цели: (a) определение природы
временного ряда и (b) прогнозирование
(предсказание будущих значений временного ряда
по настоящим и прошлым значениям). Обе эти цели
требуют, чтобы модель ряда была идентифицирована
и, более или менее, формально описана. Как только
модель определена, вы можете с ее помощью
интерпретировать рассматриваемые данные
(например, использовать в вашей теории для
понимания сезонного изменения цен на товары,
если занимаетесь экономикой). Не обращая
внимания на глубину понимания и справедливость
теории, вы можете экстраполировать затем ряд на
основе найденной модели, т.е. предсказать его
будущие значения.</p>

<p>За дополнительной информацией о временных
рядах обратитесь к разделу <a HREF="../modules/sttimser.html">Временные
ряды</a>.<br>
</p>

<p><a NAME="Jogging Weights"><font SIZE="4" COLOR="navy">Встряхивание
весов.</font></a> Добавление к весам <a HREF="gloss_n.html#Neural Networks">нейронной сети</a> небольших
случайных величин с целью обойти локальные
минимумы в пространстве ошибок. </p>

<p>См. раздел&nbsp; <a HREF="../modules/stneunet.html">Нейронные сети</a>.<br>
</p>

<p><a NAME="Outliers"><font SIZE="4" COLOR="navy">Выбросы.</font></a> По
определению, выбросы - это нетипичные или редкие
значения, которые существенно отклоняются от
распределения остальных выборочных данных. Эти
данные могут отражать истинные свойства
изучаемого явления (переменной), а могут быть
связаны с ошибками измерения или аномальными
явлениями, и поэтому не должны включаться в
модель. </p>

<p>Из-за особого способа определения линии
регрессии при вычислении <a HREF="../modules/stmulreg.html"><i>множественной
регрессии</i></a> (особенно при минимизации не сумм
отклонений, а суммы квадратов отклонений
наблюдений от линии регрессии), выбросы
оказывают существенной влияние на угол наклона
регрессионной линии и, соответственно, на
коэффициент корреляции. Всего один выброс может
полностью изменить наклон регрессионной линии и,
следовательно, вид зависимости между
переменными. Обратите внимание на следующий
рисунок. Одна точка выброса обусловливает
высокое значение коэффициента корреляции, в то
время как на самом деле (в отсутствие выброса) она
практически равна нулю. Как правило, весьма
опасно делать важные выводы о связи переменных
исключительно на основе полученного значения
коэффициента корреляции, всегда в таких случаях
имеет смысл построить и исследовать диаграмму
рассеяния. </p>

<p><img SRC="../graphics/anima3.gif" BORDER="0" alt="Диаграмма рассеяния с выбросами" WIDTH="366" HEIGHT="255"></p>

<p>Обратите внимание, что при сравнительно
маленьком объеме выборки включение или
исключение неявных &quot;выбросов&quot;&nbsp; (не таких
очевидных, как показанный на предыдущем рисунке)
может существенно изменить линию регрессии (и
коэффициент корреляции). Этот эффект показан на
следующем примере, где мы называем
&quot;выбросами&quot; исключаемые точки. Вполне
вероятно, что эти значения вовсе не являются
выбросами, а представляют собой крайние точки. </p>

<p><img SRC="../graphics/anima1.gif" BORDER="0" WIDTH="360" HEIGHT="248"></p>

<p>Обычно предполагается, что выбросы являются
случайными ошибками, влияние которых хотелось
учесть. Понятно, что выбросы могут не только
искусственно увеличить коэффициент корреляции,
но могут также и уменьшить степень
&quot;реальной&quot; зависимости.<br>
<br>
См. также раздел <a HREF="gloss_ae.html#Ellipse, (Confidence)">Доверительный
эллипс</a>.<br>
</p>

<p><a NAME="Outliers (in Box Plots)"><font SIZE="4" COLOR="navy">Выбросы (на
диаграммах размаха). </font></a>Значения, находящиеся
достаточно &quot;далеко&quot; от центра
распределения, называются выбросами (outliers) и&nbsp; <a HREF="gloss_ae.html#Extreme Values"><i>крайними точками</i></a> (extreme
values), если они удовлетворяют следующим условиям. </p>

<p><img SRC="../popups/popup105.gif" alt="Выбросы и крайние точки" WIDTH="316" HEIGHT="93"> </p>

<p>Точка данных считается <em>выбросом</em>, если:</p>

<p><font COLOR="BLUE">значение в точке &gt; ЗВГ + *к.в.*(ЗВГ -
ЗНГ)</font><br>
или<br>
<font COLOR="BLUE">значение в точке &lt; ЗНГ - *к.в.*(ЗВГ - ЗНГ)</font></p>

<p>где<br>
<font COLOR="BLUE">ЗВГ</font>&nbsp;&nbsp;- значение на верхней
границе прямоугольника на диаграмме размаха
(например, [среднее + стандартная ошибка] или [75-я
процентиль]).<br>
<font color="BLUE">ЗНГ</font>&nbsp;&nbsp;- значение на нижней
границе прямоугольника на диаграмме размаха
(например, [среднее - стандартная ошибка] или [25-я
процентиль]).<br>
<font COLOR="BLUE">к.в.</font>&nbsp;&nbsp;&nbsp;- коэффициент выброса.
</p>

<p>Например, на следующем рисунке показаны
диапазоны выбросов и <a HREF="gloss_ae.html#Extreme Values">крайних
точек</a>&nbsp; на &quot;классической&quot; <a HREF="gloss_2m.html#Box Plots, 2D">диаграмме размаха</a>
(подробнее об этом типе диаграмм можно прочитать
в работе Тьюки - Tukey, 1977). </p>

<p><img SRC="../popups/popup106.gif" alt="Диаграмма размаха" WIDTH="206" HEIGHT="282"> </p>
</body>
</html>
